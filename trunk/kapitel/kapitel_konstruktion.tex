\chapter{Architekturentwurf}
\label{Architektur-Entwurf}

Dieses Kapitel zeigt, dass die Umsetzung einer Sprchkommunikationslösung an die darunter liegende Architektur geknüpft ist. Dazu werden bestehende Architekturen für die Sprachübertragung vorgestellt und die Anforderungen und Probleme an diese beschrieben. Da noch keine strukturierte Analyse von SIP-protokoll-basierten Lösungen und ihrer Tauglichkeit für Mehrspieler-Sprach\-kommunikations\-lösungen existiert, wird diese in diesem Kapitel vorgenommen und eine Entscheidung für die Implementierung eines hybriden multi-unicast Ansatzes getroffen. Dieses Kapitel geht auch auf die resultierenden Bandbreitenprobleme der gewählten Architektur ein und stellt eigene Konzepte vor, wie anhand eines Partial-Mesh-Ansatzes, bei dem nur relevante Audioverbindungen etabliert werden, Bandbreite eingespart werden kann.

\section {Analyse der bestehenden Architekturen für Audioübertragung}

In vergleichenden Studien \cite{safei04}, \cite{safei04b} analysieren Safei und Boustead Architekturen für Sprachkommunikation in Mehrspieler-Spielen. Dazu treffen sie die Annahme, dass jeder Spieler eine Mischung aus Stimmen hören soll, die speziell auf seine Position im Spiel angepasst wird. Dies erfordert ein Abmischen der vorhandenen Audioquellen und eine Anpassung der Lautstärke der Audiosignale an deren Position in der Audioszene. Bei einer Simulation der bestehenden Architektur konzentrierten sie sich dabei auf die Fragestellung, welche Auswirkungen die Wahl einer Architektur auf das Abmischen der Audioströme hat und somit implizit auf die resultierende Netzwerklast und entstehende Verzögerungen.

Dabei führen sie auch neue Einfluss- und Messgrößen ein, die speziell im Bereich der Sprachübertragung in Spielen relevant sind: Den Begriff des "`interaktiven Delays"', die Parameter der Korrelation zwischen der physischen und der virtuellen Welt sowie der Dichte und Verteilung von Avataren. 

Die durchgeführten Simulationen sollen hier als Ausgangsgrundlage dienen und helfen, grundlegende Aussagen darüber zu treffen, wie diese Einflussgrößen die Vor- und Nachteile dieser Architekturen bestimmen.

\subsubsection{Interaktives Delay}

Als interaktives Delay wird die mittlere Verzögerung zwischen der Audioquelle und allen Zuhörern verstanden. 

	\[	
	\frac{\sum ^{N}_{i=1} d(m,n_{i})} {\sum ^{N}_{i=1} n_{i}}
\]
Dabei beschreibt $d(m,n_{i})$ die auftretende Verzögerung bei der Audioverbindung des Spielers $m$ mit dem Spieler $n_{i}$. Des interaktive Delay bietet ein gutes Maß für die Verzögerungen, die im Mittel bei allen Teilnehmern auftreten. 

\subsubsection{Avatar-Dichte}
Die Dichte der Avatare $A_{d}$ gibt an, wie viele Avatare sich in der Hörnähe des Spielers befinden. Hier gilt auch, dass verschiedene Architekturen unterschiedlich gut mit einer zunehmenden Avatardichte skalieren.  

\subsubsection{Avatar-Verteilung}
Die Verteilung der Avatare kann entweder uniform sein, bei der die Spieler zufällig gleichmäßig in der virtuellen Welt verteilt sind oder auch einzelne Ballungszentren besitzen. Um dieses Szenario zu simulieren, wurden zufällig Ballungszentren angelegt und um diese eine hohe Avatardichte erzeugt. Eine nicht uniforme Avatarverteilung ist ein oft beobachtetes Phänomen in virtuellen Welten, in denen einige \textit{Hotspots} eine hohe Avatardichte aufweisen, während diese an anderen Orten sehr gering sein kann.

\subsubsection{Korrelation}
Die Korrelation $K_{physisch-virtuell}$ zwischen der physischen und virtuellen Welt, die den Wert zwischen 0 und 1 annehmen kann, gibt an wie hoch die Wahrscheinlichkeit ist, dass Spieler sich sowohl physikalisch als auch virtuell in der Nähe befinden. Eine Korrelation von 0 bedeutet, dass die Avatare in der virtuellen Welt nicht mit der Lokation der Spieler in der physischen Welt korrelieren. %Ist auf einem Server eine hohe Korelation vorhanden, so können alle Spieler von einem niedrigen Delay ausgehen, da alle Spieler eine kurze Entfernung zum Server besitzen. 

\subsection{Peer-to-Peer}
In einer Peer-to-Peer-Architektur wird die Audioszene lokal erzeugt, nachdem man sämtliche Sprachquellen der anderen Spieler erhalten hat. Der Hauptvorteil dieser Architektur liegt darin, dass ein niedriges interaktives Delay auftritt.
Dadurch, dass eine direkte Verbindung zu jedem Spieler aufgebaut wird, fällt dieses im Vergleich zu anderen Architekturen am geringsten aus. Dies muss nicht unbedingt heißen, dass der interaktive Delay automatisch niedrig sein muss, denn das hängt davon ab, ob die Spielewelt und reale Welt korreliert sind. Wie in der Abbildung \ref{fig:entwurf-p2p} zu sehen ist, können hohe Delays auftreten, wenn Spieler auf verschiedenen Kontinenten Teil der gleichen Spielewelt sind. Ein weiterer Vorteil liegt darin, dass man die freie Rechenleistung in den Knoten nutzt, um das Abmischen der Audioszene vorzunehmen und keinen Single Point of Failure besitzt, da kein zentraler Mischserver eingesetzt wird. 

\begin{figure}[tbh]
	\centering
		\includegraphics[width=1.00\textwidth]{grafiken/entwurf-p2p.eps}
		\caption{Peer-to-Peer-Architektur mit direkten Audioverbindungen der Spieler untereinander in den entsprechenden Spielezonen}
	\label{fig:entwurf-p2p}
\end{figure}

Der Hauptnachteil dieser Topologie liegt darin, dass die Bandbreite der einzelnen Knoten im Peer-to-Peer Ansatz die Anzahl der maximal möglichen Verbindungen limitiert.
Der zweite negative Punkt besteht darin, dass die Zunahme der Avatardichte in einer Region zunächst zu einem quadratischen Anstieg der Netzwerklast führt. Dieser Punkt kann aber auch als Vorteil von Peer-to-Peer basierten Systemen verstanden werden, da zwar Avatardichte Einfluss auf die Netzwerklast hat, aber nicht die Gesamtanzahl der Spieler. Obwohl jeder Client nur seinen Teil der Spielewelt verwaltet und nur benötigte Audioverbindungen aufbaut, bleibt das Problem, dass bei einer zu hohen Avatardichte diese Architektur nicht skaliert. 

\subsection{Client-Server}
\label{client-server-verteilung}
In einer zentralisierten Lösung wird der Audiostrom von jedem der Teilnehmer an einen zentralen Audioserver gesendet. Mithilfe der Positionsdaten der Spieler wird die Audioszene dort zentral abgemischt. Diese wird danach an die jeweiligen Spieler gesendet. 

Der Hauptvorteil besteht darin, dass jeder Client auch mit beschränktem Up- und Download in der Lage ist, an solchen Konferenzen teilzunehmen. Auch die Anforderungen an die Rechenkapazität bei den Clients sind minimal, da kein lokaler Abmischvorgang stattfinden muss.  Wie Simulationen zeigen konnten verhält sich das Interaktive Delay bei einem zentralen Audioserver stabil, da weder die Zunahme der Avatardichte, noch deren Verteilung einen Einfluss auf dieses haben. 

\begin{figure}[tbh]
	\centering
		\includegraphics[width=1.00\textwidth]{grafiken/entwurf-server.eps}
	\caption{Client-Server-Architektur mit zentralem Mischserver in Nordamerika}
	\label{fig:entwurf-server}
\end{figure}

 Der Nachteil einer zentralen Komponente ist, dass für die Teilnehmer große Delays auftreten können, wenn sie sich physikalisch weit entfernt vom Server befinden. Diese hängen bei einem zentralisierten System  stark von dessen Standort ab und können bei einem falsch positioniertem Server entsprechend schlecht ausfallen (siehe Abbildung \ref{fig:entwurf-server} Teilnehmer 6,7 und 8).
 
 Möchte man den Teilnehmern die Kontrolle über alle Audioströme überlassen und findet kein Mischvorgang auf dem Server statt, so erschöpft sich schnell seine Kapazität, da für $N$ eingehende Audioströme $N^2-N$ ausgehende Ströme verschickt werden müssen. 

Ein fundamentaler Nachteil des Systems bleibt jedoch seine fehlende Skalierbarkeit, da sich ab einer zu großen Gesamtspieleranzahl sich sowohl die Leistungs- als auch die Bandbreitenkapazitäten des Servers erschöpfen. Um die Last zu verteilen, werden nachfolgend zwei alternative Systeme vorgestellt.

Spieler der gleichen Umgebung der realen Welt werden an den gleichen Audioserver verwiesen, was dem "`Audio-Proxy"'-Konzept entspricht. Das Konzept der "`verteilten Audioserver"' sieht vor, dass Spieler der gleichen Umgebung der virtuellen Welt dem gleichen Server zugeteilt werden.

\subsubsection{Audio-Proxy}
\label{Audio-Proxy}
Zunächst muss festgehalten werden, dass der Begriff Proxy hier anders als in der Literatur üblich verwendet wird. Als Proxy, werden in Rechnernetzen normalerweise Vermittler bezeichnet, die auf der einen Seite Anfragen entgegennehmen, um dann über seine eigene Adresse eine Verbindung zur anderen Seite herzustellen. Wenn hier vom Audio-Proxy gesprochen wird, ist nicht nur diese Funktionalität gemeint, sondern auch die Funktion, dass der Audio-Proxy Audioströme abmischen und an Clients oder andere Proxys verschicken kann.

In einer Audio-Proxy-Lösung existieren Server, die weltweit verteilt sind und so immer eine geringe Entfernung zum Teilnehmer ermöglichen sollen. Diese empfangen die Audioströme der Clients, mischen diese ab und schicken sie an die jeweiligen Spieler zurück. Proxys können ebenfalls Audioströme an weitere Proxys weiterleiten, falls diese benötigt werden. 

Die Vorteile dieses Konzepts liegen darin, dass im Gegensatz zur Peer-to-Peer-Architektur durch den Einsatz von dedizierten Proxys mit guter Anbindung Bandbreitenprobleme minimiert werden. Bei einer Zunahme der Gesamtanzahl der Spieler helfen Proxys auch die Last des zentralisierten Systems zu verteilen, da sie Audioströme verteilt entgegennehmen und mischen können. Gegeben den Fall, dass eine starke Korrelation zwischen der realen und virtuellen Welt herrscht, können Audio-Proxys durch ihre ebenso guten Bandbreiten und Leistungskapazitäten auch Änderungen der Avatardichte oder der Avatarverteilung gut handhaben. Dies ist deswegen der Fall, da sich nur bei einer starken Korrelation Spieler, der gleichen Audioumgebung in der Spielewelt auch in physikalischer Nähe befinden und so kurze Entfernungen zum Server besitzen. 

\begin{figure}[tbh]
	\centering
		\includegraphics[width=1.00\textwidth]{grafiken/entwurf-proxy.eps}
	\caption{Beispiel für eine Proxy-Architektur. In schwarz ist die Verbindung von Spieler 3 mit Spieler 7 dargestellt.}
	\label{fig:entwurf-proxy}
\end{figure}

Jedoch kann eine Korrelation beider Welten nicht forciert werden, was auch den Hauptnachteil dieses Systems ausmacht. Man kann durch das Proxy Konzept zwar erzwingen, dass Spieler der gleichen Umgebung in der realen Welt den gleichen Proxy benutzen, kann sie aber nicht in der Bewegung in der virtuellen Welt einschränken, da sie sich ja frei bewegen sollen. Umso mehr Teilnehmer sich in der Umgebung des Spielers befinden und so die Avatardichte erhöhen, desto mehr steigt die Wahrscheinlichkeit, dass auch mehrere verschiedene Proxys eingesetzt werden müssen, um die Audioszene zu mischen. Dies führt wiederum dazu, dass mehr Nachrichten zwischen den Proxys untereinander weitergeleitet werden müssen, was letztendlich zu einer Verschlechterung des interaktiven Delays führt.

\subsubsection{Verteilte Audioserver}
\label{verteilteaudioserver}
In einer verteilten Server-Lösung ist jeder zentrale Server nur für einen Teil der Spielewelt verantwortlich. So nutzen Spieler, die sich in der gleichen virtuellen Umgebung befinden den gleichen Server, der ihre Audioströme abmischt. Dieser Ansatz kann die auftretenden Kapazitätsprobleme einer zentralisierten Lösung reduzieren, in dem die Last auf mehrere Server verteilt wird. Die Netzwerklast hängt auch hier wie bei allen Serversystemen von der Gesamtspieleranzahl auf dem jeweiligen Server ab. 

Verteilte Audioserver bieten die gleichen Vorteile wie Audio-Proxys, besitzen jedoch auch die gleichen Nachteile. Wie bei den Audio-Proxys gilt auch hier, dass dieses System bei einer starken Korrelation beider Welten gut funktioniert, diese aber nicht erzwungen werden kann. Man kann zwar durch das verteilte Server-Konzept erzwingen, dass Spieler der gleichen Umgebung in der virtuellen Welt den gleichen Server benutzen, hat dann aber keinen Einfluss darauf, wie ihre Verteilung in der realen Welt ist, da man von überall am Spiel teilnehmen kann. 

Ähnlich wie beim Proxy-Konzept hat hier eine Zunahme der Avatardichte einen negativen Einfluss auf das interaktive Delay. Mit einer Zunahme erhöht sich die Chance, dass Spieler der gleichen Spielregion aus verschiedenen Teilen der Welt stammen können. Diese Tatsache erhöht die Wahrscheinlichkeit, dass der entsprechende Server sich nicht im "`Schwerpunkt"' aller Spieler befindet. Somit kann das jeweilige Delay für einige Spieler sehr gut ausfallen, für andere jedoch sehr schlecht.

\begin{figure}
	\centering
		\includegraphics[width=1.00\textwidth]{grafiken/entwurf-verteilteserver.eps}
	\caption{Verteilte Server S1...S4. Die Verbindungen der Spielewelt S2 werden in schwarz dargestellt. }
	\label{fig:entwurf-verteilteserver}
\end{figure} 

Neue Probleme entstehen beim Übergang von einem Server zum anderen. Wenn Teilnehmer während des Spiels die Spielzone wechseln und ihre Audioströme nun von einem anderen Server abgemischt werden sollen, können Server abhängig von ihrer Lage unterschiedlich hohe Delays liefern und in Grenzbereichen der Spielewelt Probleme auftreten, da der Audioserver oft gewechselt wird.

\subsection{Hybrid}
Im Ansatz einer Hybrid-Architektur senden die Teilnehmer ihre Audioströme zwar an einen zentralisierten Server, können sie aber bei Bedarf auch direkt austauschen, wenn die indirekte Route über den Server zu zu hohen Delays führen würde. Der hybride Ansatz könnte zwar alle Vorteile von Peer-to-Peer-Systemen mit zentralisierten Systemen kombinieren, ist allerdings nicht einfach umzusetzen, da nicht klar definiert ist, wann ein Teilnehmer zentral abgemischt werden soll und wann der Audiostrom direkt zwischen den Clients ausgetauscht wird und zudem eine hohe Koordination zwischen den Teilnehmern erfordert.

\section {Architekturen mit SIP-Komponenten}
Entsprechend der vorgestellten Architekturen gibt es mehrere Möglichkeiten, Konferenzen mit mehreren Teilnehmern in SIP zu realisieren. 

Prinzipiell müssen aber bei einer Umsetzung zwei Fragen beantwortet werden:

\begin{itemize}
	\item Wie und wo findet die Signalisierung der Konferenzen und die Lokation der Teilnehmer statt?
	\item Wie und wo findet das Abmischen des Audiostroms statt?
\end{itemize}

%Auch interessant:
%http://www.ietf.org/internet-drafts/draft-ietf-simple-simple-02.txt

Diese zwei Aspekte können nicht getrennt voneinander betrachtet werden, da immer die Wahl einer Architektur Einfluss auf beide Probleme hat. In einer Peer-to-Peer basierten Architektur ist es z. B. zunächst keine triviale Aufgabe, eine Lokation aller Teilnehmer vorzunehmen, da jeder Peer nur einen Teil der Spielewelt verwaltet und keine zentralisierte Instanz existiert, die über alle Positionen aller Spieler verfügt.  Genauso ergeht es dem zentralisierten System, in dem die Lokation und Signalisierung der Teilnehmer zwar durch eine zentrale Komponente einfach ist, aber eine Verteilung des Audiostroms, problematisch ist. 

So muss für Konferenzen nicht nur die Frage beantwortet werden wo der Audiostrom abgemischt wird, sondern wie die Teilnehmer informiert werden, dass sie Teil einer Konferenz sind.

Zusätzlich zu diesen Fragen muss eine gewählte Architektur in Bezug auf die Herausforderungen aus Kapitel 3 noch folgende Kriterien erfüllen:

\begin{itemize}
	\item Die Architektur muss mehrere Audioströme unterstüzen.
	\item Jeder Client muss in der Lage sein alle Audioströme lokal zu kontrollieren.
\end{itemize}

%Deswegen werden die Komponenten zur Lokation, Signalisierung der Konferenzen und Mischen des Audiostroms zwar gleichzeitig betrachtet, aber unter ihnen unterschieden.

\subsection{Komponenten}
Es können drei Hauptkomponenten eines Systems definiert werden, die je nach ihrer Verteilung verschiedene Architekturen bilden können:

\begin{itemize}
	\item \textbf{Mixer}: Ein Mixer empfängt eine Gruppe von Audioströmen und vereinigt ihre Medien nach einer spezifischen Art, um das Ergebnis an jeden Teilnehmer zu schicken. Dies beinhaltet Medien, die mittels des RTP-Protokolls übertragen wurden.
	\item \textbf{Konferenz-Komponente:} Ein Konferenz-Komponente ist die logische Instanz, die darüber entscheidet, welche Audioströme miteinander gemischt werden, an wen sie verteilt werden und auch wer Teilnehmer einer Konferenz ist. Die Konferenz-Komponente kann von der Spielelogik gesteuert werden. Im SIP-Standard beinhaltet diese Komponente einen Proxy und/oder Registrar. 
	\item \textbf{Teilnehmer-Client}: Eine Client-Anwendung verbindet einen Benutzer mit einer Konferenz. Diese implementiert mindestens einen SIP-User-Agent kann aber auch nicht SIP spezifische Mechanismen für zusätzliche Funktionalität beherbergen. 
	%\item \textbf{Spieleserver}: Eine optionale Komponente, die die Daten der Spieler entgegen nimmt, um sie auszuwerten und an die anderen Teilnehmer zu verteilen. Diese kann, muss aber nicht, die Spielelogik enthalten und teilt dem Konferenz-Server mit, welche Spieler Teil einer Konferenz werden. Um mit den anderen Komponenten zu kommunizieren unterstützt sie das SIP Protokoll. 
\end{itemize}

%\subsection{Einsatz mehrerer Server}
%\label{mehrereregistrare}

Aus den vorgestellten Komponeten wird ersichtlich, dass die Architektur der Sprachkommunikation nicht getrennt von der Architektur des darunter liegenden Signalisierung gesehen werden kann. Dies geschieht deswegen, weil die Signalisierung und der reine Austausch an Spielerinformationen und Konferenzinformationen relativ wenig Bandbreite benötigt. Eine Audioverbindung dagegen, kann aufgrund ihres reinen Datenvolumens bereits das zehnfache der Bandbreite benötigen.   

Geht man davon aus, dass sowohl die Signalisierung, als auch die Audioströme zwischen den Spielern entweder komplett zentral, verteilt oder komplett dezentral stattfinden können, ergeben sich 9 mögliche Kombinationen, die in Tabelle \ref{audiodatenmatrix} dargestellt werden. Dabei kann beim verteilen von Audioservern jede Technik aus Abschnitt \ref{client-server-verteilung} eingesetzt werden.

\begin{table}[tbh]
	\centering	\begin{tabular}{p{0.2\textwidth}|p{0.2\textwidth}|p{0.2\textwidth}|p{0.2\textwidth}}		
		\toprule
		\textbf{Daten / \newline Audio} & \textbf{Zentral} & \textbf{Verteilt} & \textbf{P2P} \\
		\midrule
		\textbf{Zentral} & ($A_{1}$) Client-Server Paradigma & ($A_{4}$) Ein Audioserver und mehrere Datenserver & ($A_{7}$) Ein Audioserver, aber dezentrale Signalisierung\\
		\hline
		\textbf{Verteilt} & ($A_{2}$) Zentraler Server mit mehreren dedizierten Audioservern & ($A_{5}$) Supernodes Konzept& ($A_{8}$) Dedizierte Audiomixer, dezentrale Signalisierung\\
		\hline
		\textbf{P2P} & ($A_{3}$) VoIP mit zentralem Server & ($A_{6}$) VoIP mit verteilten Servern & ($A_{9}$) Komplett dezentrale Lösungen. \\
		\bottomrule
		\end{tabular}
	\label{audiodatenmatrix}
	\caption{Mögliche Kombinationen bei Unterscheidung zwischen Daten- und Audioströmen}
\end{table}

Prinzipiell sind alle Alternativen vorstellbar. In erster Linie sollen bei einer Implementierung einer einsatzfähigen Sprachkommunikationslösung vor allem Alternativen bevorzugt werden, die sowohl umsetzbar als auch sinnvoll erscheinen, als auch eine Umsetzung der Vorschläge aus Kapitel 3 erfüllen können.  

\begin{itemize}
	\item ($A_{1}$) Hier findet sowohl die Signalisierung und Lokation der Teilnehmer als auch das Mischen des Audiostroms zentral statt. Darunter versteht man ein SIP-Netzwerk, das mit einem zentralen Server ausgestattet ist, der sämtliche Daten der Spielerclients entgegennimmt und alle Konferenzen koordiniert. Das Abmischen der Audioströme findet ebenfalls in einer oder mehreren zentralen Konferenzen statt, die auf dem Server verwaltet werden. 	
	\item ($A_{2}$) Behält man eine zentrale Konferenzkomponente bei, geht aber von einem verteilten Abmischen der Audioströme aus, kann man entweder mehrere dedizierte Mixer einsetzen oder auch einzelne Clients mit genügend Bandbreite (Superpeers) nutzen, um den Audiostrom zu mischen und dann zu verteilen (siehe Abschnitt \ref{verteilteaudioserver} und \ref{Audio-Proxy})
	\item ($A_{3}$) Im hybriden Modell besitzt das System einen zentralen Proxy und Registrar, der die Signalisierung und Lokation der Teilnehmer vornimmt; das Abmischen der Audioströme findet dagegen dezentral von jedem Client statt. Dies entspricht dem ursprünglichen SIP-Aufbau, bei dem die Sprachkommunikation zwischen den einzelnen Peers stattfindet und das Audiosignal lokal von jedem Teilnehmer abgemischt wird.
	\item ($A_{4}$) Setzt man mehrere Proxys oder verteilte Server für den Datenaustausch ein, mischt aber die Audioströme zentral ab, so braucht man einen dedizierten Mixer, der alle Audioströme entgegen nimmt und abmischt, während die Sig\-nali\-sierung über mehrere Proxys verteilt wird. 
	\item ($A_{5}$): Realisiert man sowohl den Datenaustausch als auch das Mischen des Audiostroms verteilt, kann man davon ausgehen dass entweder dedizierte Audio- und Datenkomponenten zusammenarbeiten oder auch ein Netzwerk aus Client-Superpeers gebildet wird. Hier wird von gut angebundenen Knoten die Signalisierung und das Mischen des Audiostroms vornehmen. 
	\item ($A_{6}$): Diese Alternative entspricht der vorhergehenden Alternative, nur dass hier jeder Clients für das Abmischen seines Audiostroms verantwortlich ist, während die Signalisierung und Lokation von verteilten Proxys oder Registraren übernommen wird.
	\item ($A_{7}$): Hier liegt ein komplett dezentraler Datenaustausch mit einem zentralen Audioserver
	\item ($A_{8}$): Es handelt sich um einen Ein komplett dezentralen Datenaustausch mit mehreren Audioservern.
	\item ($A_{9}$): Realisiert man sowohl den Datenaustausch als auch das Mischen des Audiostroms komplett dezentral, 	spricht man vom Einsatz eines dezentralisierten SIP-Netzwerkes, das mittels P2P-SIP, Multicast oder Full-Mesh-Ansätzen realisiert werden kann. 
\end{itemize}

Die vorgestellten Alternativen $A_{5}$ und $A_{6}$, gehen davon die zentrale Komponente des Registrars verteilbar ist. Von einer Verteilung des Registrars und Proxy können auch die vorgestellten Alternativen $A_{1}$, $A_{2}$, $A_{3}$ profitieren, da sich damit die \textit{Fault Tolerance} des Systems erhöht. Falls mehrere Registrare eingesetzt werden, bestehen folgende Alternativen\footnote{Die Nachteile dieser Ansätze bei einer großen Benutzeranzahl sind entweder eine große Netzwerklast oder eine hohe Verbindungslatenz.}:
\begin{itemize}
	\item Die Registrierung des Benutzers findet auf einem Registrar statt und wird dann mit Datenbank-Replikation konsistent auf mehrere Registrare repliziert werden. Die Suche findet bei einem beliebigen Registrar statt.  
	\item Die Registrierung geschieht nur auf einem Registrar, während die Suche nach dem Registrar, der die Benutzerinformation enthält vom Client auf allen Registraren stattfindet. Dazu muss der Benutzer alle Registrare kontaktieren oder der erste kontaktierte Server die Anfrage weiterleiten. 
\end{itemize}

%Der Nachteil des ersten Ansatzes ist eine erforderliche Synchronisation für jede Registrierung. Es besteht die Möglichkeit, dass Einträge veraltet sind, bevor eine Synchronisation zwischen den Servern ausgeführt wird. Mit einer wachsenden Anzahl an Benutzern könnte der zusätzliche Netzwerkverkehr zwischen den Servern zu einem Flaschenhals werden. 

%Im anderen Fall ist die Verbindungslatenz höher, da erst eine Reihe von Schritten durchlaufen werden muss. Eine parallele Suche erhöht zudem die benötigte Bandbreite. 

%Beide Ansätze können jedoch fehlschlagen, wenn die Anzahl an Benutzern sehr groß wird.

Geht man dazu über, den Datenaustausch des Spiels auf dezentral zu verteilen (siehe Alternativen $A_{7}$,$A_{8}$,$A_{9}$), so geschieht das aus zwei Gründen: Erstens um einen Single Point of Failure zu vermeiden und zweitens um eine bessere Skalierbarkeit zu erreichen. 

Prinzipiell ist dieses Vorgehen solange praktikabel wie noch einige zentrale Komponenten bestehen, die hierarchisch höher gestellt sind als andere Knoten. Dies ist schon aus Gründen wie z. B. der Konferenzsteuerung notwendig, da Knoten existieren müssen, die die Lokationen der einzelnen Teilnehmer kennen, Rechte in Konferenzen überwachen, oder eine Liste an aktiven Teilnehmern führen.

 Ansätze zu einer komplett dezentralen Signalisierung werden später im Kapitel 8 vorgestellt, es darf aber schon vorab festgehalten werden, dass ein hoher Aufwand betrieben werden muss, um skalierbare dezentrale Systeme zu konstruieren. Nimmt man  diesen Aufwand tatsächlich auf sich, so erscheint es unlogisch, noch zentrale Audioserver Komponenten zu behalten, da man so wieder einen Single Point of Failure besitzt. Das führt zur logischen Entscheidung, alle Kombinationen, die eine dezentrale Signalisierung besitzen, die aber trotzdem zentrale Audioserver einsetzen, nicht weiter zu analysieren. Davon sind die Alternativen ($A_{7}$) und ($A_{8}$) betroffen.

Genauso verhält es sich bei der Skalierbarkeit: Der Grund mehrere Server einzusetzen liegt - wie bereits erwähnt - darin, die ansteigende Netzwerklast zu verteilen. Behält man jedoch einen einzigen zentralen Audioserver bei, so bildet dieser schnell den Flaschenhals. Deswegen wird die Alternative ($A_{4}$), die verteilte Spieleserver aber einen zentralen Audioserver einsetzt, vorerst nicht weiter untersucht.

Die verbleibenden Alternativen lassen sich in 4 Gruppen gliedern:
\begin{itemize}
	\item Komplett dezentralisierte Ansätze (Alternative $A_{9}$)
	\item Komplett zentralisierte Ansätze (Alternative $A_{1}$)
	\item Ansätze, die verteiltes dediziertes Audiomixing vornehmen (Alternativen $A_{2}$ und $A_{5}$)
	\item Ansätze, die komplett dezentrales Audiomixing vornehmen (Alternativen $A_{3}$ und $A_{6}$)
\end{itemize}

\subsection{Komplett dezentralisierte Ansätze}

\begin{figure}[tbh]
	\centering
		\includegraphics[width=0.60\textwidth]{grafiken/archp2p.eps}
	 \caption{Dezentralisierte SIP Architektur}
	\label{fig:archp2p}
\end{figure}

Ansätze der Alternative $A_{9}$ haben alle gemeinsam, dass sowohl der Audiostrom, als auch der Datenstrom nur zwischen den einzelnen Knoten fließt und keine zentrale Komponente benötigt wird. Sie unterscheiden sich jedoch darin, in welchen Topologien die einzelnen Clients miteinander verbunden werden und auf welche Art und weise die Signalisierung stattfindet. Alle komplett dezentralisierten Ansätze sind sehr gute Kandidaten um die Anforderungen aus Kapitel 3 zu erfüllen, da hier jeder Client über mit allen Audioströmen versorgt wird. Der Nachteil solcher Architekturen liegt jedoch in der schwierigen Signalisierung der Teilnehmer, da sich diese in einem komplett Verteilten System schwierig gestaltet. 

\subsubsection{Multicast}
Groß angelegte Multicast-Konferenzen waren die ursprüngliche Motivation für die Entwicklung von SIP. In solchen Konferenzen werden eine oder mehrere Multicast-Konferenzen zu einer Konferenz vereint. Jeder Teilnehmer tritt einer Multicast-Gruppe bei und sendet seine Daten an diese Gruppe. 

Multicast-Konferenzen haben den Vorteil, dass sie keine Koordination zwischen den Endsystemen benötigen. Konferenzteilnehmer können unabhängig einer Konferenz beitreten und sie verlassen. 

Der Hauptnachteil von Multicast ist jedoch, dass es nur in einem Local Area Network funktioniert und im Internet nicht allgemein verfügbar ist. Zudem müssen bei solchen Konferenzen Router die Identitäten der Gruppe speichern und es ist beliebigen Teilnehmern möglich, solchen Gruppen ohne Authentifizierung beizutreten. 

So verlieren die Teilnehmer die Kontrolle darüber, wer an Konferenzen teilnehmen kann und sind auch nicht in der Lage zu wissen, wer ihnen gerade zuhört. Ist bereits ein System falsch konfiguriert können Anwender alle existierenden-Multicast Gruppen abonnieren und so das Netz schnell fluten. Gerade wegen dieser Probleme wird Multicast in wenigen Internet-Hauptleitungen unterstützt. So können Multicast-Konferenzen zwar in LANs nützlich sein, sind jedoch im kommerziellen Internet nicht umsetzbar.

% In the loosely coupled model, there is no signaling relationship between participants in the conference.  There is no central point of control or conference server.  Participation is gradually learned through control information that is passed as partof the conference (using the Real Time Control Protocol (RTCP) [2], for example).  Loosely coupled conferences are easily supported in SIP by using multicast addresses within its session descriptions. 

\subsubsection{Peer-to-Peer Unicast}
\label{peer-to-peer-unicast}
Bei einem völlig dezentralisierten P2P-SIP mittels verteilter \textit{Hashtabellen}\footnote{siehe Kapitel 9} findet sowohl die Lokation, Signalisierung als auch die Sprachkommunikation nur zwischen den einzelnen Clients statt. Dazu wird zentrale Komponente des Registrars wird auf die einzelnen Clients verteilt. Für jede Audioverbindung wird ein Peer-to-Peer Unicast eingesetzt, dessen Vor- und Nachteile in Abschnitt \ref{siphybrid} besprochen werden.

Dieser interessante Ansatz ist bisher nur theoretisch möglich, da keine geeignete SIP-Implementierung existiert, die einen verteilten Registrar umsetzt. Zudem ist das Problem einer verteilten Spielkontrolle nicht trivial, da kein Teilnehmer über komplette Informationen der Spielewelt verfügt. Dieses Problem wird später genauer in Kapitel 9 behandelt. Sollte in Zukunft eine Implementierung eines funktionierenden P2P-SIP-Overlays existieren, könnte diese Option in Zukunft durchaus vorstellbar sein. 

\subsubsection{Full-Mesh}
In einem "`Full-Mesh"'-Modell kommuniziert jeder Endpunkt direkt mit jedem anderen Endpunkt. Alle Teilnehmer in der Konferenz sind "`gleich"' - es gibt keinen Benutzer, der topologisch besonders ist oder über zusätzlichen Rechte oder Fähigkeiten verfügt. Jeder Teilnehmer kann jederzeit eine Konferenz betreten und verlassen. Das Audiosignal wird nur von den Endpunkten abgemischt.

Der Hauptvorteil ist, dass kein Endsystem mehr als einen Audiostrom encodieren muss. Jeder Benutzer dekodiert bis zu N-1 Audioströme einer N-Teilnehmer Konferenz, muss aber nur einen Audiostrom enkodieren. Für die meisten Sprachcodecs verursacht das Enkodieren mehr Last als das Dekodieren, was also zunächst nicht problematisch ist. 

In einer N-Teilnehmer Konferenz muss jedoch jeder Teilnehmer über genügend Bandbreite verfügen, um N-1 simultane Audioströme zu verschicken. Dadurch ist dieser Mechanismus für Systeme mit limitierten Bandbreiten wie analoge Modems oder asymmetrische DSL-Leitungen mit einem schwachen Upload nicht besonders gut anwendbar.

Das größte Problem bei diesem Ansatz stellt jedoch die fehlende strukturierte Signalisierung und Lokalisierung der Teilnehmer dar, da kein Knoten eine vollständige Information darüber besitzt, wer Teil einer Konferenz sein soll. Der in Kapitel 5 vorgestellte Full-Mesh-Ansatz von Schulzrinne enthält genau diese Problematik.

\subsection{Komplett zentralisierte Ansätze}
\label{zentralansatz}

\begin{figure}[tbh]
	\centering
		\includegraphics[width=0.60\textwidth]{grafiken/archzentral.eps}
	\caption{Komplett zentralisierter Ansatz mit SIP}
	\label{fig:archzentral}
\end{figure}

Die in Kapitel 5 von Singh und Acharya vorgestellte Methode kann man als zentralisiertes SIP bezeichnen. Hier wird die Signalisierung und Lokation der Teilnehmer und das Abmischen der Audioströme zentral vorgenommen. Den komplett zentralisierten Ansatz verfolgen auch Safei und Boustead im vorgestellten MICE-System. Diese Architektur bietet zunächst eine sehr gute Ausgangsbasis für Sprachkommunikationslösungen mit einer begrenzten Anzahl an Teilnehmern, da es auch Knoten mit geringer Bandbreite eine Teilnahme ermöglicht. 

Die Grundlage für eine einfache Berechnung der maximal möglichen Anzahl an Spielern auf einem Server versteht sich unter folgenden Voraussetzungen:

\begin{itemize}
	\item Jeder Spieler sendet einen Audiostrom zum Server.
	\item Jeder Spieler im gleichen Spiel möchte die gesprochenen Daten aller Spieler empfangen.
	\item Weil der Spiele- / Konferenzserver und Mixer zentralisiert sind, kann der Mixer die Audioströme zentral abmischen, da er auch die Positionen der Teilnehmer kennt. 
\end{itemize}

Befinden sich beispielsweise 16 Personen im Spiel, empfängt der Server Audio\-ströme von 16 Personen und sendet einen bereits abgemischten Audiostrom an jede der 16 Personen. 

Sendet jeder Spieler seinen Audiostrom mit einem Speex\footnote{Patentfreies Audio-Kompressions-Format (Xiph OSC) , Version 22.03.2008, http://speex.org} Audiocodec mit einer 16 Kbit/s Bitrate an den Server, der nach dem heutigem Standard mit einer 100MBit-Anbindung für den Up- und Download ausgestattet ist, würde sich folgende theoretische maximale Anzahl an gleichzeitigen Audioverbindungen ergeben:

\[
 \frac{100000 \frac{Kbit}{s}}{16 \frac{Kbit}{s}} = 6250 \, Spieler
\]

Der Client selbst dagegen muss nur in der Lage sein, seinen eigenen Audiostrom zu senden und einen Audiostrom mit gleicher Bitrate zu empfangen. 

Obwohl diese Rechnung zunächst vielversprechend klingt, muss auch die Rechenkapazität des Servers berücksichtigt werden, da jedes der ankommenden Signale dekodiert, abgemischt und enkodiert werden muss. Eine Messung\footnote{Siehe Kapitel 10 evaluation} der CPU-Belastung des Mixers, die Anhand der Implementierung vorgenommen wurde, zeigt dass die theoretische Grenze von 6250 Spielern schon mitunter bei 32 Spielern erreicht wird und so die mögliche Anzahl an Spielern vor allem durch die hohe CPU-Belastung des Mixers begrenzt wird. 

Prinzipiel ist dieser Ansatz allen dezentralisierten Ansätzen überlegen, da ein zentraler Mischserver in der Regel über genügend Bandbreite verfügt, um viele Audioströme zu empfangen und zu versenden, während dies bei Clients oft zu Problemen führt. Zudem besteht die Möglichkeit, die Lokation und Signalisierung der Teilnehmer zentral zu verwalten. Diese Architektur wird vor allem bei Telefonkonferenzen verwendet, bei denen die Endgeräte (VoIP-Telefone) die über eine geringe Rechenleistung verfügen und auf das Abmischen des Audiosignals durch einen Mischserver angewiesen sind. 

Die Nachteile eines zentralen Mischservers überwiegen seine Vorteile: Zum einen ergeben sich Schwierigkeiten bei der Skalierbarkeit\footnote{Die maximale Anzahl gleichzeitiger Spieler auf einem Server liegt bei bisherigen Lösungen bei ca. 200 Teilnehmern (Ventrilo).}Grenzen bisheriger Sprachkommunikations eines einzigen zentralen Audioservers, da dessen Bandbreite und Rechnerkapazität begrenzt sind. Dazu kommt das bereits in Abschnitt \ref{client-server-verteilung} beschriebene Problem des interaktiven Delays, der abhängig von der Position des Servers entsprechend schlecht ausfallen kann. Da in Kapitel 3 auch gefordert wurde, dass jeden Spieler Kontrolle über alle seine Audioströme erhalten soll, gestaltet sich außerdem die Verwaltung und das Abmischen einer jeweils persönlichen Konferenz für jeden Spieler sehr schwer. Zu allerletzt bleiben noch die hohen Kosten beim Einsatz eines zentralen dedizierten Servers. All diese Gründe haben sprechen gegen die Favorisierung einer  solchen Architektur. 

Dabei bietet es sich gerade im Spielebereich an, die hohe Rechenleistung von gut ausgestatteten Spielecomputern auszunutzen, um die zentrale Komponente zu entlasten. 

\subsection{Verteiltes dediziertes Audiomixing}
\begin{figure}
	\centering
		\includegraphics[width=0.70\textwidth]{grafiken/archverteilt.eps}
	\caption{Architekturen mit dedizierten Audiomixern}
	\label{fig:archverteilt}
\end{figure}

 Ein Ansatz verteilte Konferenzen zu betreiben, besteht darin, mehrere dedizierte SIP-Endpunkte zu ernennen, mit denen sich Teilnehmern verbinden. Diese Mixer nehmen die Audioströme entgegen, mischen sie ab und leiten sie an die entsprechenden Spieler weiter. Die Signalisierung dagegen kann entweder von einem oder mehreren Registraren vorgenommen werden. 

Dabei gibt es zwei mögliche Varianten dieses Modells: In einem Superpeer-Mixing übernimmt ein Teilnehmer die Verantwortung für das Mischen des Audiostroms und in einem Server-basierten-Mixing übernehmen unabhängige dedizierte Server-Knoten diese Verantwortung, ohne aktiv am Gespräch teilzunehmen. 

Die Vorteile liegen vor allem in der Verteilung der Bandbreiten- und Kapazitätsbelastung des Mischvorgangs auf mehrere Maschinen während die Signalisierung noch zentral verwaltet werden kann. 

Dieses Modell hat jedoch einige Nachteile: Vor allem beim Einsatz von Superpeer-Mixing ist die Existenz einer Konferenz ab\-hän\-gig von dem Vorhandensein des entsprechenden Knotens, geht dieser offline, kann das Abmischen nicht mehr stattfinden. Was die maximale Anzahl an Spielern angeht, ergeben sich hier prinzipiell für jeden Mischknoten die gleichen Berechnungen wie bei einem einzigen Server System (siehe Abschnitt \ref{zentralansatz}). Es erscheint unwahrscheinlich, dass private Rechner heutzutage über genügend Bandbreite und Rechenkapazität verfügen, um für eine signifikante Anzahl an Spielern das Mischen vorzunehmen. Setzt man ein Server-basiertes-Mixing ein, so sind entsprechend hohe Kosten bei deren Betrieb zu tragen. Radenkovic et al setzen ein 

Ebenfalls problematisch gestaltet sich das Auffinden von Superpeer-Mixern, da zuerst alle Teilnehmer den gleichen Knoten aufsuchen müssen, um diesem dann die Kontrolle über die Konferenz zu übergeben. Das dies keine einfache Aufgabe ist, zeigt der im Kapitel 5 vorgestellte Ansatz von Gu, der sich mit der Kontrolle von dedizierten \textit{Superpeers} beschäftigt. Dort wird auch nicht auf das Problem eingegangen, wie solche Mischknoten lokalisiert werden sollen und wie die Übergänge zwischen verschiedenen Konferenzen stattfinden sollen. Genauso unzureichend kann auch der Ansatz des Distributed Partial Mixing aus Kapitel 5 alle auftretenden Probleme lösen.

Unabhängig davon welches Verfahren verwendet wird, kommen immer beim verteilten Abmischen von Audiosignalen die Probleme der Korrelation (siehe Abschnitt \ref{Audio-Proxy} ) der Spieler hinzu, die die Effizienz dieses Verfahrens deutlich reduzieren. 

Man kann eingeschränkt sagen, dass dedizierte Knoten besser als Superpeers für dieses Verfahren geeignet sind, da diese meist zuverlässiger sind und über eine bessere Anbindung verfügen. Für größere Konferenzen, bei denen die einzelnen Teile der Spielewelt von einzelnen Audioproxys verwaltet werden, bietet sich diese Art des Mischens zwar an, aber für kleine persönliche Konferenzen bedeutet sie einen erheblichen Aufwand. Die Anforderung, dass jeder einzelne Client eine Kontrolle über seine Audioströme haben soll, ist bei dieser Architektur nur mit einer komplizierten Signalisierung möglich. 
% Grafik End-System-Mixing
% Grafik Server-Based-Mixing

\subsection{Hybrides Peer-to-Peer Audiomixing}
\label{siphybrid}

\begin{figure}
	\centering
		\includegraphics[width=0.60\textwidth]{grafiken/archhybrid.eps}
	\caption{Hybride SIP Architektur mit einem oder mehreren Konferenzservern}
	\label{fig:archhybrid}
\end{figure}

Bei diesem Ansatz wird das Abmischen der Audioströme direkt von den einzelnen Clients vorgenommen, während die Signalisierung von einem oder mehreren Registraren übernommen wird. Im einfachsten Fall wird der eigene Audiostrom an alle Teilnehmer des Spieles gesendet (Multi-Unicast), und man selbst empfängt auch den Audiostrom aller Teilnehmer. In einer Konferenz mit $n$ Teilnehmern müssen so insgesamt $n^2-n$ Audioströme ausgetauscht werden. 

Was den Austausch der Audiosignale betrifft, entspricht diese Architektur dem Full-Mesh-Anatz von Schulzrinne \cite{schulzrinne03}. Da die Signalisierung beim Full-Mesh-Ansatz keine zentrale Komponente besitzt, liegt große Nachteil darin die Teilnehmer einer Konferenz zu bestimmen. Hier kann jedoch die Bestimmung der Teilnehmer einer Konferenz mit Hilfe des Registrars zentral geschehen und löst dieses Problem. 

Indem die einzelnen Client-Knoten, die gerade im Spielebereich sehr gut ausgesattet sind, das Abmischen vornehmen, kann die Kapazitätsbelastung eines Mischservers so verteilt werden. Da allerdings der Bandbreitenverbrauch bei einem dezentralen Austausch von Audioströmen quadratisch von der Anzahl der Teilnehmer abhängt, soll eine Plausibilitätsrechnung prüfen, welche Mindestvoraussetzungen die Teilnehmer eines solchen Systems erfüllen müssen.

Es wird gefordert, dass mindestens 16 Spieler in der Lage sein sollen, miteinander zu kommunizieren. Sendet jeder Spieler seinen Audiostrom mit 16 Kbit/s an die anderen Spieler, kann leicht errechnet werden, über welche Anbindung die Spieler mindestens verfügen müssen, um diese Anforderung zu erfüllen. 

Die Grundlage für eine einfache Berechnung bieten die folgenden Voraussetzungen:

\begin{itemize}
	\item Jeder Spieler sendet einen Audiostrom an alle Clients.
	\item Jeder Spieler im gleichen Spiel möchte die Audioströme aller Personen empfangen.
	\item Jeder Spieler mischt die Audioströme lokal ab, da er auch die Positionen der Teilnehmer kennt. 
\end{itemize}

Befinden sich beispielsweise 16 Personen im Spiel, empfängt jede dieser 16 Personen 16 Audioströme und sendet auch seinen eigenen Audiostrom an jede der 16 Personen. 

Upstream/Downstream:

\[	
	\mbox{16 Spieler} \cdot 16 \frac{Kbit}{s} = 256 \frac{Kbit}{s}
\]

Jeder Spieler muss also über mindestens $256 Kbit/s$ Up- Download verfügen, um in einem Full-Mesh miteinander kommunizieren zu können. Der Full-Mesh Ansatz hat das Problem, dass sich die Kapazität der Bandbreite relativ schnell erschöpft, da jeder Spieler seinen Audiostrom an alle anderen Spieler senden muss. Geht man davon aus, dass jeder Client heutzutage mit einem Upload von 128 Kbit/s ausgestattet ist, zeigen sich bereits bei 16 Spielern, die Grenzen dieses Systems. Mit entsprechenden Audiocodecs ist vielleicht eine Verdopplung der Teilnehmer möglich, sie ändert aber nichts an den architekturbedingten Grenzen dieses Ansatzes.

Die Gründe dafür liegen unter anderem in einer uneffizienten Verbreitung des Audiostroms. Es ist vorstellbar, dass nicht jeder Spieler des Spiels an den Audioströmen aller Mitspieler interessiert ist. Trotzdem werden mit allen Teilnehmern Verbindungen aufgebaut. Deswegen werden in den folgenden Abschnitten Methoden vorgestellt, die Ansätze aus Kapitel 3 nutzen, um Bandbreite einzusparen.

Diese Alternative bietet als einzige die entsprechenden Eigenschaften, um die Ansätze aus Kapitel 3 umzusetzen. Sie bietet wie alle dezentralen Alternativen $A9$ dem Client Kontrolle über alle Audioströme und erlaubt so mehrere Kanäle gleichzeitig zu verwenden und lokal abgemischen, verfügt jedoch als einzige über eine funktionierende bereits praxisbewährte Signalisierung.  Diese besteht in der zentralen Komponente des Registrars, der es erlaubt eine einfache Lokation und Signalisierung der Teilnehmer vorzunehmen. Bei P2P-SIP-Ansätzen befindet sie sich noch noch im Entwurfstadium oder ist beim Full-Mesh-Ansatz besonders kompliziert. 

Außerdem nutzt der Hybride Ansatz genau die Unterschiede der beiden Daten- und Audioströme, was dazu führt, dass der Bandbreitenverbrauch auf den zentralen Komponenten ist minimal ist, da der Audiostrom nur zwischen den Clients fließt. Dies erlaubt es auch günstige zentrale Komponenten einzusetzen. 

Außerdem bietet der hybride Ansatz eine gute Ausgangsgrundlage, um eine völlig dezentralisiere Sprachkommunikation mit P2P-SIP zu ermöglichen, indem die einzige zentrale Komponente des Registrars verteilt wird. 

\section{Möglichkeiten zur Einsparung von Bandbreite}

\subsection{Hörnähe vs. Area of Interest}
Da bereits in Kapitel 3 festgestellt wurde, dass Spieler nur an manchen  Audioströmen von Spielern interessiert sind, wird versucht diese Beobachtung in die Modellierung einfließen zu lassen. Muss jeder Teilnehmer seinen Audiostrom nicht an alle anderen Teilnehmer verschicken, sondern nur an Teilnehmer seiner unmittelbaren Umgebung, so kann Bandbreite eingespart werden. %Außerdem kann in Abhängigkeit der Entfernung der Spieler zueinander, unterschieden werden welcher Audiocodec eingesetzt wird. 

Dieser Ansatz entspricht dem Proximitätsprinzip, oder auch der \textit{Area of Interest}, bei der nur Teilnehmer an einer Audioverbindung interessiert sind, die sich auch tatsächlich in der Nähe des Spielers befinden.

Die Grundlage für eine einfache Berechnung versteht sich unter folgenden Voraussetzungen:

\begin{itemize}
	\item Jeder Spieler sendet einen Audiostrom an Teilnehmer in seiner Hörnähe. 
	\item Jeder Spieler befindet sich mit einer Wahrscheinlichkeit $P_{Hoernaehe}$ in der Hörnahe des Teilnehmers. 
	\item Jeder Spieler mischt die Audioströme lokal ab, da er auch die Positionen der Teilnehmer kennt. 
\end{itemize}

Befinden sich beispielsweise 16 Personen im Spiel und nimmt man an, dass sich im Schnitt nur $30\%$ aller Teilnehmer in Hörnähe aufhalten, so muss der Sender nur noch an 5 Personen seinen Audiostrom senden und auch nur von 5 Personen den Audiostrom empfangen. 

Dabei gibt $P_{Hoernaehe}$ an, wie viele Personen, sich im Schnitt in der Hörnähe des Teilnehmers befinden. Dieser Wert kann verändert werden, in dem die \textit{Hörer\-reichweite} des Spielers vergrößert oder verkleinert wird. 

Generell gilt je größer die Hörerreichweite, desto mehr Personen können sich in der Hörnähe des Teilnehmers befinden. In dieser Arbeit wird bei einer Hörerreichweite von 10 m eine theoretische Wahrscheinlichkeit von 30\% angenommen, dass eine Person sich in diesem Hörradius befindet . 

Nun wird die Gleichung um diese Wahrscheinlichkeit ergänzt und immer noch von 16 Spielern im Spiel ausgegangen. 

Upstream/Downstream:

\[
	\mbox{16 Spieler} \cdot 16 \frac{Kbit}{s} \cdot 30\% = 76,8\frac{Kbit}{s}
\]

In Abhängigkeit von der Wahrscheinlichkeit ist eine Reduzierung der Bandbreite möglich. Natürlich kann im schlechtesten Fall, bei einer hohen Avatardichte, der Fall eintreten, dass wieder alle 16 Teilnehmer sich in der Hörnähe des Spielers befinden. Dann ist diese Lösung genauso effizient wie die Full-Mesh-Topologie, da der Spieler mit allen Teilnehmern Verbindungen aufbauen muss. Im Schnitt kann jedoch ein großer Prozentsatz der Bandbreite eingespart werden, wenn man davon ausgeht, dass Spieler nur an Audioverbindungen mit Spielern interessiert sind, die sich in ihrer Nähe befinden.

\subsection{Private Zone und Soziale Zone}

Es lässt sich sogar noch mehr Bandbreite einsparen, wenn man die Hörreichweite in zwei Zonen (entsprechend Abschnitt \ref{proxemikalssteuerungvonkonferenzen}) mit verschiedenen Audiocodecs unterteilt. In einer private Zone wird ein hochwertiger Audiocodec mit einer größeren Bandbreite benutzt und in einer sozialen Zone ein wird ein Codec mit einer niedrigeren Bandbreite benutzt. 

In einem einfachen Szenario, kann man annehmen, dass die 30\% aller Benutzer in Hörreichweite, sich zu 10\% in der privaten Zone und zu 20\% in der sozialen Zone aufhalten. Spieler in der privaten Zone nutzen einen Audiocodec mit einer Bitrate von $16 Kbit/s$ und Spieler in der sozialen Zone einen Audiocodec mit $8 Kbit/s$. Ergänzt man die Gleichung entsprechend um das Zonenkonzept, und nimmt immer noch an, dass sich 16 Spieler im Spiel befinden kommt man zu folgender Berechnung:

\[
	\mbox{16 Spieler} \cdot 16 \frac{Kbit}{s} \cdot 10\% + \mbox{16 Spieler} \cdot 16 \frac{Kbit}{s} \cdot 20\% = 51,2\frac{Kbit}{s}
\]

Hier wird deutlich, dass noch einmal Bandbreite eingespart werden kann, und trotzdem die gleiche Konnektivität gewährleistet wird. Die Einsparung resultiert vor allem aus der Reduziertung der Audioqualität der sozialen Zone. Trotzdem kann bei Bedarf noch eine höherwertige Konversation eingeleitet werden, indem sich Spieler in die private Zone begeben. Im Kapitel 7 und 9 wird die Umsetzung dieses Ansatzes genauer diskutiert und evaluiert.
\cleardoublepage

