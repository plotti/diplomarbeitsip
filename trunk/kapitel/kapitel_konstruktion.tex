\chapter{Architektur-Entwurf}
\label{Architektur-Entwurf}

Dieses Kapitel zeigt, dass die Umsetzung einer Sprchkommunikationslösung an die darunter liegende Architektur geknüpft ist. Dazu werden bestehende Architekturen für die Sprachübertragung vorgestellt und die Anforderungen und Probleme an diese beschrieben. Da noch keine strukturierte Analyse von SIP-protokoll-basierten Lösungen und ihrer Tauglichkeit für Mehrspieler-Sprach\-kommunikations\-lösungen existiert, wird diese in diesem Kapitel vorgenommen und eine Entscheidung für die Implementierung eines hybriden multi-unicast Ansatzes getroffen. Dieses Kapitel geht auch auf die resultierenden Bandbreitenprobleme der gewählten Architektur ein und stellt eigene Konzepte vor, wie anhand eines Partial-Mesh-Ansatzes, bei dem nur relevante Audioverbindungen etabliert werden, Bandbreite eingespart werden kann.

\section {Analyse der bestehenden Architekturen für Audioübertragung}

In vergleichenden Studien \cite{safei04}, \cite{safei04b} analysieren Safei und Boustead Architekturen für Sprachkommunikation in Mehrspieler-Spielen. Dazu treffen sie die Annahme, dass jeder Spieler eine Mischung aus Stimmen hören soll, die speziell auf seine Position im Spiel angepasst wird. Dies erfordert ein Abmischen der vorhandenen Audioquellen und eine Anpassung der Lautstärke der Audiosignale an deren Position in der Audioszene. Bei einer Simulation der bestehenden Architektur konzentrierten sie sich dabei auf die Fragestellung, welche Auswirkungen die Wahl einer Architektur auf das Abmischen der Audioströme hat und somit implizit auf die resultierende Netzwerklast und entstehende Verzögerungen.

Dabei führen sie auch neue Einfluss- und Messgrößen ein, die speziell im Bereich der Sprachübertragung in Spielen relevant sind: Den Begriff des "`interaktiven Delays"', die Parameter der Korrelation zwischen der physischen und der virtuellen Welt sowie der Dichte und Verteilung von Avataren. 

Die durchgeführten Simulationen sollen hier als Ausgangsgrundlage dienen und helfen, grundlegende Aussagen darüber zu treffen, wie diese Einflussgrößen die Vor- und Nachteile dieser Architekturen bestimmen.

\subsubsection{Interaktiver Delay}

Als interaktiver Delay wird der mittlere Delay zwischen der Audioquelle und allen Zuhörern verstanden. 

	\[	
	\frac{\sum ^{N}_{i=1} d(m,n_{i})} {\sum ^{N}_{i=1} n_{i}}
\]
Dabei beschreibt $d(m,n_{i})$ den auftretenden Delay bei der Audioverbindung des Spielers $m$ mit dem Spieler $n_{i}$. Der interaktive Delay bietet ein gutes Maß für die Verzögerungen, die im Mittel bei allen Teilnehmern auftreten. 

\subsubsection{Avatar-Dichte}
Die Dichte der Avatare $A_{d}$ gibt an, wie viele Avatare sich in der Hörnähe des Spielers befinden. Hier gilt auch, dass verschiedene Architekturen unterschiedlich gut mit einer zunehmenden Avatardichte skalieren.  

\subsubsection{Avatar-Verteilung}
Die Verteilung der Avatare kann entweder uniform sein, bei der die Spieler zufällig gleichmäßig in der virtuellen Welt verteilt sind oder auch einzelne Ballungszentren besitzen. Um dieses Szenario zu simulieren, wurden künstlich zufällig Ballungszentren angelegt und um diese eine hohe Avatardichte erzeugt. Eine nicht uniforme Avatarverteilung ist ein oft beobachtetes Phänomen in virtuellen Welten, in denen einige \textit{Hotspots} eine hohe Avatardichte aufweisen, während diese an anderen Orten sehr gering sein kann.

\subsubsection{Korrelation}
Die Korrelation $K_{physisch-virtuell}$ zwischen der physischen und virtuellen Welt, die den Wert zwischen 0 und 1 annehmen kann, gibt an wie hoch die Wahrscheinlichkeit ist, dass Spieler sowohl physikalisch als auch virtuell sich in der Nähe befinden. Eine Korrelation von 0 bedeutet, dass die Avatare in der virtuellen Welt nicht mit der Lokation der Spieler in der physischen Welt korrelieren. %Ist auf einem Server eine hohe Korelation vorhanden, so können alle Spieler von einem niedrigen Delay ausgehen, da alle Spieler eine kurze Entfernung zum Server besitzen. 

\subsection{Peer-to-Peer}
In einer Peer-to-Peer Architektur wird die Audioszene lokal erzeugt, nachdem man sämtliche Sprachquellen der anderen Spieler erhalten hat. Der Hauptvorteil dieser Architektur liegt darin, dass ein niedriger interaktiver Delay auftritt.
Dadurch, dass eine direkte Verbindung zu jedem Spieler aufgebaut wird, fällt dieser im Vergleich mit anderen Architekturen am geringsten aus. Dies muss nicht unbedingt heißen, dass der interaktive Delay automatisch niedrig sein muss, denn das hängt davon ab, ob die Spielewelt und reale Welt korreliert sind. Wie in der Abbildung \ref{fig:entwurf-p2p} zu sehen ist, können hohe Delays auftreten, wenn Spieler auf verschiedenen Kontinenten Teil der gleichen Spielewelt sind. Ein weiterer Vorteil liegt darin, dass man die freie Rechenleistung in den Knoten nutzt, um das Abmischen der Audioszene vorzunehmen und keinen Single Point of Failure besitzt, da kein zentraler Mischserver eingesetzt wird. 

\begin{figure}[tbh]
	\centering
		\includegraphics[width=1.00\textwidth]{grafiken/entwurf-p2p.eps}
		\caption{Peer-to-Peer-Architektur mit direkten Audioverbindungen der Spieler untereinander in den entsprechenden Spielezonen}
	\label{fig:entwurf-p2p}
\end{figure}

Der Hauptnachteil dieser Topologie liegt darin, dass die Bandbreite der einzelnen Knoten im Peer-to-Peer Ansatz die Anzahl der maximal möglichen Verbindungen limitiert.
Der zweite negative Punkt besteht darin, dass die Zunahme der Avatardichte in einer Region zunächst zu einem quadratischen Anstieg der Netzwerklast führt. Dieser Punkt kann aber auch als Vorteil von Peer-to-Peer basierten Systemen verstanden werden, da zwar Avatardichte Einfluss auf die Netzwerklast hat, aber nicht die Gesamtanzahl der Spieler. Obwohl jeder Client nur seinen Teil der Spielewelt verwaltet und nur benötigte Audioverbindungen aufbaut, bleibt das Problem, dass bei einer zu hohen Avatardichte diese Architektur nicht skaliert. 

\subsection{Client-Server}
In einer zentralisierten Lösung wird der Audiostrom von jedem der Teilnehmer an einen zentralen Audioserver gesendet. Mithilfe der Positionsdaten der Spieler wird die Audioszene dort zentral abgemischt. Diese wird danach an die jeweiligen Spieler gesendet. 

Der Hauptvorteil besteht darin, dass jeder Client auch mit beschränktem Up- und Download in der Lage ist an solchen Konferenzen teilzunehmen. Auch die Anforderungen an die Rechenkapazität bei den Clients sind minimal, da kein lokaler Abmischvorgang stattfinden muss.  Wie Simulationen zeigen konnten verhält sich der Interaktive Delay bei einem zentralen Audioserver stabil, da weder die Zunahme der der Avatardichte, noch deren Verteilung einen Einfluss auf ihn haben. 

\begin{figure}[tbh]
	\centering
		\includegraphics[width=1.00\textwidth]{grafiken/entwurf-server.eps}
	\caption{Client Server Architektur mit zentralem Mischserver in Nordamerika}
	\label{fig:entwurf-server}
\end{figure}

 Der Nachteil einer zentralen Komponente ist, dass für die Teilnehmer große Delays auftreten können, wenn sie sich physikalisch weit vom Server befinden. Diese hängen bei einem zentralisierten System  stark von dessen Standort ab und können bei einem falsch positioniertem Server entsprechend schlecht ausfallen (siehe Abbildung \ref{fig:entwurf-server} Teilnehmer 6,7 und 8)
 
 Möchte man den Teilnehmern die Kontrolle über alle Audioströme überlassen und findet kein Mischvorgang auf dem Server statt, erschöpft sich schnell seine Kapazität, da für $N$ eingehende Audioströme $N^2$ ausgehende Ströme verschickt werden müssen. 

Ein fundamentaler Nachteil des Systems bleibt jedoch seine fehlende Skalierbarkeit, da ab einer zu großen Gesamtspieleranzahl sich sowohl die Leistungs- als auch die Bandbreitenkapazitäten des Servers erschöpfen. Um die Last zu verteilen, wurden zwei alternative Systeme vorgestellt.

Spieler der gleichen Umgebung der realen Welt werden an den gleichen Audioserver verwiesen, was dem "`Audio-Proxy"'-Konzept entspricht. Das Konzept der "`verteilten Audioserver"' sieht vor, dass Spieler der gleichen Umgebung der virtuellen Welt dem gleichen Server zugeteilt werden.

\subsubsection{Audio-Proxy}
\label{Audio-Proxy}
Zunächst muss festgehalten werden, dass der Begriff Proxy hier anders als in der Literatur üblich verwendet wird. Als Proxy, werden normalerweise in Rechnernetzen Vermittler bezeichnet, die auf der einen Seite Anfragen entgegennehmen, um dann über seine eigene Adresse eine Verbindung zur anderen Seite herzustellen. Wenn hier vom Audio-Proxy gesprochen wird, ist nicht nur diese Funktionalität gemeint, sondern auch die Funktion, dass der Audio-Proxy Audioströme abmischen und an Clients oder andere Proxys verschicken kann.

In einer Audio-Proxy Lösung existieren Server, die weltweit verteilt sind und so immer eine geringe Entfernung zum Teilnehmer ermöglichen sollen. Diese empfangen die Audioströme der Clients, mischen diese ab und schicken sie an die jeweiligen Spieler zurück. Proxys untereinander können ebenfalls Audioströme an weitere Proxys weiterleiten, falls diese benötigt werden. 

Die Vorteile dieses Konzepts liegen darin, dass im Gegensatz zur Peer-to-Peer Architektur durch den Einsatz von dedizierten Proxys mit guter Anbindung Bandbreitenprobleme minimiert werden. Bei einer Zunahme der Gesamtanzahl der Spieler helfen Proxys auch die Last des zentralisierten Systems zu verteilen, da sie Audioströme verteilt entgegennehmen und mischen können. Gegeben den Fall, dass eine starke Korrelation zwischen der realen und virtuellen Welt herrscht, können Audio-Proxys durch ihre ebenso guten Bandbreiten und Leistungskapazitäten auch Änderungen der Avatardichte, oder der Avatarverteilung gut handhaben. Dies ist deswegen der Fall, da nur bei einer starken Korrelation Spieler, der gleichen Audioumgebung in der Spielewelt sich auch in räumlicher Nähe befinden und so kurze Delays untereinander auftreten. 

\begin{figure}[tbh]
	\centering
		\includegraphics[width=1.00\textwidth]{grafiken/entwurf-proxy.eps}
	\caption{Eine Proxy-Architektur. In schwarz ist die Verbindung von Spieler 3 mit Spieler 7 dargestellt.}
	\label{fig:entwurf-proxy}
\end{figure}

Jedoch kann eine Korrelation beider Welten nicht forciert werden, was auch den Hauptnachteil dieses Systems ausmacht. Man kann durch das Proxy Konzept zwar erzwingen, dass Spieler der gleichen Umgebung in der realen Welt den gleichen Proxy benutzen, kann sie aber nicht in der Bewegung in der virtuellen Welt einschränken, da sie sich ja frei bewegen sollen. Umso mehr Teilnehmer sich in der Umgebung des Spielers befinden und so die Avatardichte erhöhen, desto mehr steigt die Wahrscheinlichkeit, dass auch mehrere verschiedene Proxys eingesetzt werden müssen, um die Audioszene zu mischen. Dies führt wiederum dazu, dass mehr Nachrichten zwischen den Proxys untereinander weitergeleitet werden müssen, was letztendlich zu einer Verschlechterung des interaktiven Delays führt.

\subsubsection{Verteilte Audioserver}
\label{verteilteaudioserver}
In einer verteilten Server-Lösung ist jeder zentrale Server nur für einen Teil der Spielewelt verantwortlich. So nutzen Spieler, die sich in der gleichen virtuellen Umgebung befinden den gleichen Server, der ihre Audioströme abmischt. Dieser Ansatz kann die auftretenden Kapazitätsprobleme einer zentralisierten Lösung reduzieren, in dem die Last auf mehrere Server verteilt wird. Die Netzwerklast hängt auch hier wie bei allen Serversystemen von der Gesamtspieleranzahl auf dem jeweiligen Server ab. 

Verteilte Audioserver bieten die gleichen Vorteile wie Audio-Proxys, besitzen jedoch auch die gleichen Nachteile. Wie bei den Audio-Proxys gilt auch hier, dass dieses System bei einer starken Korrelation beider Welten gut funktioniert, diese aber nicht erzwungen werden kann. Man kann zwar durch das Verteilte Server-Konzept erzwingen, dass Spieler der gleichen Umgebung in der virtuellen Welt den gleichen Server benutzen, hat dann aber keinen Einfluss darauf, wie ihre Verteilung in der realen Welt ist, da man von überall am Spiel teilnehmen kann. 

Ähnlich wie beim Proxy Konzept, hat hier eine Zunahme der Avatardichte einen negativen Einfluss auf den interaktive Delay. Mit einer Zunahme erhöht sich die Chance, dass Spieler der gleichen Spielregion aus verschiedenen Teilen der Welt stammen können. Diese Tatsache erhöht die Wahrscheinlichkeit, dass der entsprechende Server sich nicht im "`Schwerpunkt"' aller Spieler befindet. Somit kann der jeweilige Delay für einige Spieler sehr gut ausfallen, für andere jedoch sehr schlecht.

\begin{figure}
	\centering
		\includegraphics[width=1.00\textwidth]{grafiken/entwurf-verteilteserver.eps}
	\caption{Verteilte Server S1...S4. Die Verbindungen der Spielewelt S2 werden in schwarz dargestellt. }
	\label{fig:entwurf-verteilteserver}
\end{figure} 

Neue Probleme entstehen beim Übergang von einem Server zum anderen: Wenn Teilnehmer während des Spiels die Spielzone wechseln und ihre Audioströme nun von einem anderen Server abgemischt werden sollen, können Server je nach ihrer Lage unterschiedlich hohe Delays liefern und in Grenzbereichen der Spielewelt Probleme auftreten, da der Audioserver oft gewechselt wird.

\subsection{Hybrid}
Im Ansatz einer Hybrid Architektur senden die Teilnehmer ihre Audioströme zwar an einen zentralisierten Server, können sie aber bei Bedarf auch direkt austauschen, wenn die indirekte Route über den Server zu zu hohen Delays führen würde. Der Hybride Ansatz könnte zwar alle Vorteile von Peer-to-Peer-Systemen mit zentralisierten Systemen kombinieren, ist allerdings nicht einfach umzusetzen, da nicht klar definiert ist, wann ein Teilnehmer zentral abgemischt werden soll und wann der Audiostrom direkt zwischen den Clients ausgetauscht wird und zudem eine hohe Koordination zwischen den Teilnehmern erfordert.

\section {Architekturen mit SIP Komponenten}
Entsprechend der vorgestellten Architekturen gibt mehrere Möglichkeiten Konferenzen mit mehreren Teilnehmern in SIP zu realisieren. 

Prinzipiell müssen aber bei einer Umsetzung zwei 2 Fragen beantwortet werden:

\begin{itemize}
	\item Wie und wo findet die Signalisierung der Konferenzen und die Lokation der Teilnehmer statt?
	\item Wie und wo findet das Abmischen des Audiostroms statt?
\end{itemize}

%Auch interessant:
%http://www.ietf.org/internet-drafts/draft-ietf-simple-simple-02.txt

Diese zwei Aspekte können nicht getrennt voneinander betrachtet werden, da immer die Wahl einer Architektur Einfluss auf beide Probleme hat. In einer Peer-to-Peer basierten Architektur ist es z.B. zunächst keine triviale Aufgabe, eine Lokation aller Teilnehmer vorzunehmen, da jeder Peer nur einen Teil der Spielewelt verwaltet und keine zentralisierte Instanz existiert, die über alle Positionen aller Spieler verfügt.  Genauso ergeht es dem zentralisierten System, in dem die Lokation und Signalisierung der Teilnehmer zwar durch eine zentrale Komponente einfach ist, aber eine Verteilung des Audiostroms, problematisch ist. 

So muss für Konferenzen nicht nur die Frage beantwortet werden wo der Audiostrom abgemischt wird, sondern wie die Teilnehmer informiert werden, dass sie Teil einer Konferenz sind.

%Deswegen werden die Komponenten zur Lokation, Signalisierung der Konferenzen und Mischen des Audiostroms zwar gleichzeitig betrachtet, aber unter ihnen unterschieden.

\subsection{Komponenten}
Es können vier Hauptkomponenten eines Systems definiert werden, die je nach ihrer Verteilung verschiedene Architekturen bilden können:

\begin{itemize}
	\item \textbf{Mixer}: Ein Mixer empfängt eine Gruppe von Audioströmen und vereinigt ihre Medien nach einer spezifischen Art, um das Ergebnis an jeden Teilnehmer zu schicken. Dies beinhaltet Medien, die mittels des RTP-Protokolls übertragen wurden.
	\item \textbf{Konferenz-Server:} Ein Konferenz-Server ist die logische Instanz, die darüber entscheidet welche Audioströme miteinander gemischt werden und an wen sie verteilt werden. 
	\item \textbf{Teilnehmer-Client}: Eine Client Anwendung, die einen Benutzer mit einer Konferenz verbindet. Diese implementiert mindestens einen SIP-User-Agent kann aber auch nicht SIP spezifische Mechanismen für zusätzliche Funktionalität beherbergen. 
	\item \textbf{Spieleserver}: Eine optionale Komponente, die die Daten der Spieler entgegen nimmt, um sie auszuwerten und an die anderen Teilnehmer zu verteilen. Diese kann, muss aber nicht, die Spielelogik enthalten und teilt dem Konferenz-Server mit, welche Spieler Teil einer Konferenz werden. Um mit den anderen Komponenten zu kommunizieren unterstützt sie das SIP Protokoll. 
\end{itemize}

Aus den vorgestellten Komponeten wird ersichtlich, dass die Architektur der Sprachkommunikation nicht getrennt von der Architektur des darunter liegenden Spieles gesehen wird. Während die Signalisierung und der reine Austausch an Spielerinformationen und Konferenzinformationen relativ wenig Bandbreite benötigt, kann eine Audioverbindung aufgrund ihres reinen Datenvoluments bereits das 10fache der Bandbreite benötigen. 

Geht man davon aus, dass sowohl der Datenverkehr, als auch die Audioströme zwischen den Spielen entweder komplett zentral, verteilt oder komplett dezentral stattfinden können, ergeben sich 9 mögliche Kombinationen, die in Tabelle \ref{audiodatenmatrix} dargestellt werden: 

\begin{table}[tbh]
	\centering	\begin{tabular}{p{0.2\textwidth}|p{0.2\textwidth}|p{0.2\textwidth}|p{0.2\textwidth}}		
		\toprule
		\textbf{Daten / \newline Audio} & \textbf{Zentral} & \textbf{Verteilt} & \textbf{P2P} \\
		\midrule
		\textbf{Zentral} & ($A_{1}$) Client-Server Paradigma & ($A_{4}$) Ein Audioserver und mehrere Datenserver & ($A_{7}$) Ein Audioserver, aber dezentrale Signalisierung\\
		\hline
		\textbf{Verteilt} & ($A_{2}$) Zentraler Server mit mehreren dedizierten Audioservern & ($A_{5}$) Supernodes Konzept& ($A_{8}$) Dedizierte Audiomixer, dezentrale Signalisierung\\
		\hline
		\textbf{P2P} & ($A_{3}$) VoIP mit zentralem Server & ($A_{6}$) VoIP mit verteilten Servern & ($A_{9}$) Komplett dezentrale Lösungen. \\
		\bottomrule
		\end{tabular}
			\label{audiodatenmatrix}
	\caption{Mögliche Kombinationen bei Unterscheidung zwischen Daten- und Audioströmen}
\end{table}

Prinzipiell sind alle Alternativen vorstellbar. In erster Linie sollen bei einer Implementierung einer einsatzfähigen Sprachkommunikationslösung vor allem Alternativen bevorzugt werden, die sowohl umsetzbar als auch sinnvoll erscheinen.  

\begin{itemize}
	\item ($A_{1}$) Hier findet sowohl die Signalisierung und Lokation der Teilnehmer als auch das Mischen des Audiostroms zentral statt. Darunter versteht man ein SIP Netzwerk, das mit einem zentralen Server ausgestattet ist, der sämtliche Daten der Spielerclients entgegen nimmt und verteilt. Das Abmischen der Audioströme findet ebenfalls in einer zentralen Konferenz statt, die auf dem Server verwaltet wird. 	
	\item ($A_{2}$) Behält man eine zentrale Konferenzkomponente bei, geht aber von einem verteilten Abmischen der Audioströme aus, kann man entweder mehrere dedizierte Mixer einsetzen oder auch einzelne Clients mit genügend Bandbreite (Superpeers) nutzen, um den Audiostrom zu mischen und dann zu verteilen (siehe Abschnitt \ref{verteilteaudioserver} und \label{Audio-Proxy})
	\item ($A_{3}$) Im Hybriden Modell besitzt das System einen zentralen Proxy und Registrar, der die Signalisierung und Lokation der Teilnehmer vornimmt; das Abmischen der Audioströme findet dagegen dezentral statt. Dies entspricht dem ursprünglichen SIP-Aufbau, bei dem die Sprachkommunikation zwischen den einzelnen Peers stattfindet und das Audiosignal lokal von jedem Teilnehmer abgemischt wird.
	\item ($A_{4}$) Setzt man mehrere Proxys oder verteilte Server für den Datenaustausch ein, mischt aber die Audioströme zentral ab, so braucht man einen dedizierten Mixer, der alle Audioströme entgegen nimmt, während die Sig\-nali\-sierung über mehrere Proxys verteilt wird. 
	\item ($A_{5}$): Realisiert man sowohl den Datenaustausch als auch das Mischen des Audiostroms verteilt, kann man davon ausgehen dass entweder dedizierte Audio- und Datenkomponenten zusammenarbeiten oder auch ein Netzwerk aus Client Superpeers gebildet wird. Hier wird von gut angebundenen Knoten das Mischen des Audiostroms vorgenommen und dann verteilt. 
	\item ($A_{6}$): Diese Alternative entspricht der vorhergehenden Alternative, nur dass hier der Audiostrom direkt zwischen den einzelnen Clients fließt, während die Signalisierung und Lokation von verteilten Proxys und Registraren übernommen wird.
	\item ($A_{7}$): Ein komplett dezentraler Datenaustausch mit einem zentralen Audioserver
	\item ($A_{8}$): Ein komplett dezentraler Datenaustausch mit mehreren Audioservern  
	\item ($A_{9}$): Realisiert man sowohl den Datenaustausch als auch das Mischen des Audiostroms komplett dezentral, 	spricht man vom Einsatz eines dezentralisierten SIP-Netzwerkes, das mittels P2PSIP, Multicast oder Full-Mesh Ansätzen realisiert werden kann. 
\end{itemize}

Geht man dazu über, den Datenaustausch des Spiels auf mehrere Server zu verteilen (siehe Alternativen $A_{7}$,$A_{8}$,$A_{9}$), so tut man das aus zwei Gründen: Erstens um einen Single Point of Failure zu vermeiden und zweitens um eine bessere Skalierbarkeit zu erreichen. 

Prinzipiell ist dieses Vorgehen solange praktikabel wie noch einige zentrale Komponenten bestehen, die hierarchisch höher gestellt sind als andere Knoten. Dies ist schon aus Gründen wie z.B. der Konferenzsteuerung notwendig, da Knoten existieren müssen, die die Lokationen der einzelnen Teilnehmer kennen, Rechte in Konferenzen überwachen, oder eine Liste an aktiven Teilnehmern führen.

 Ansätze zu einer komplett dezentralen Signalisierung werden später im Kapitel 8 vorgestellt, es darf aber schon vorab festgehalten werden, dass ein hoher Aufwand betrieben werden muss, um skalierbare dezentrale Systeme zu konstruieren. Nimmt man  diesen Aufwand tatsächlich auf sich, so erscheint es unlogisch, noch zentrale Audioserver Komponenten zu behalten, da man so wieder einen Single Point of Failure besitzt. Das führt zur logischen Entscheidung, alle Kombinationen, die eine dezentrale Signalisierung besitzen, die aber trotzdem zentrale Audioserver einsetzen, nicht weiter zu analysieren. Davon sind die Alternativen ($A_{7}$) und ($A_{8}$) betroffen.

Genauso verhält es sich bei der Skalierbarkeit: Der Grund mehrere Server einzusetzen liegt - wie bereits erwähnt - darin die ansteigende Netzwerklast zu verteilen. Behält man jedoch einen einzigen zentralen Audioserver bei, bildet dieser schnell den Flaschenhals. Deswegen wird die Alternative ($A_{4}$), die verteilte Spieleserver, aber einen zentralen Audioserver einsetzt, vorerst nicht weiter untersucht.

Die verbleibenden Alternativen lassen sich in 4 Gruppen gliedern:
\begin{itemize}
	\item Komplett dezentralisierte Ansätze (Alternative $A_{9}$)
	\item Komplett zentralisierte Ansätze (Alternative $A_{1}$)
	\item Ansätze, die verteiltes dediziertes Audiomixing vornehmen (Alternativen $A_{2}$ und $A_{5}$)
	\item Ansätze, die komplett dezentrales Audiomixing vornehmen (Alternativen $A_{3}$ und $A_{6}$)
\end{itemize}


\subsection{Komplett dezentralisierte Ansätze}
Ansätze der Alternative $A_{9}$ haben alle gemeinsam, dass sowohl der Audiostrom, als auch der Datenstrom nur zwischen den einzelnen Knoten fließt und keine zentrale Komponente benötigt wird. Sie unterscheiden sich jedoch darin, in welchen Topologien die einzelnen Clients miteinander verbunden werden und auf welche Art und weise die Signalisierung stattfindet. 

\subsubsection{Multicast}
Groß angelegte Multicast-Konferenzen waren die ursprüngliche Motivation für die Entwicklung von SIP. In solchen Konferenzen werden eine oder mehrere Multicast Konferenzen zu einer Konferenz vereint. Jeder Teilnehmer tritt einer Multicast Gruppe bei und sendet sein Medium an diese Gruppe. 

Multicast-Konferenzen haben den Vorteil, dass sie keine Koordination zwischen den Endsystemen benötigen. Konferenzteilnehmer können unabhängig einer Konferenz beitreten und sie verlassen. 

Der Hauptnachteil von Multicast ist jedoch, dass es nur in einem Local Area Network funktioniert und im Internet nicht allgemein verfügbar ist. Zudem müssen bei solchen Konferenzen Router die Identitäten der Gruppe speichern und es ist beliebigen Teilnehmern möglich solche Gruppen ohne Authentifizierung beizutreten. 

So verlieren die Teilnehmer die Kontrolle darüber, wer an Konferenzen teilnehmen kann und sind auch nicht in der Lage zu wissen, wer ihnen gerade zuhört. Ist bereits ein System falsch konfiguriert könnte alle existierenden Multicast Gruppen abonnieren und so das Netz schnell fluten. Gerade wegen dieser Probleme wird Multicast in wenigen Internet Hauptleitungen unterstützt. So können Multicast Konferenzen zwar in LANs nützlich sein, sind jedoch im kommerziellen Internet nicht umsetzbar.

% In the loosely coupled model, there is no signaling relationship between participants in the conference.  There is no central point of control or conference server.  Participation is gradually learned through control information that is passed as partof the conference (using the Real Time Control Protocol (RTCP) [2], for example).  Loosely coupled conferences are easily supported in SIP by using multicast addresses within its session descriptions. 

\subsubsection{Peer-to-Peer Unicast}
\label{peer-to-peer-unicast}
Bei einem völlig dezentralisierten P2P SIP mittels verteilter \textit{Hashtabellen} findet sowohl die Lokation und Signalisierung als auch die Sprachkommunikation nur zwischen den einzelnen Clients statt. Die zentrale Komponente des Registrars wird auf die einzelnen Clients verteilt. Für jede Audioverbindung wird ein Peer-to-Peer Unicast eingesetzt. 

Dieser interessante Ansatz ist bisher nur theoretisch möglich, da keine geeignete SIP Implementierung existiert, die einen verteilten Registrar umsetzt. Zudem ist das Problem einer verteilten Spielkontrolle nicht trivial, da kein Teilnehmer über komplette Informationen über die Spielewelt verfügt. Dieses dieses Problem wird später genauer in Kapitel 9 behandelt. Sollte in Zukunft eine Implementierung eines funktionierenden P2PSIP Overlays existieren, könnte diese Option in Zukunft durchaus vorstellbar sein. Dieses Konzept erfordert ein komplett dezentrales Abmischen der Audioströme, dessen Vor- und Nachteile in Abschnitt \ref{siphybrid} besprochen werden.

\subsubsection{Full-Mesh}
In einem "`Full-Mesh"' Modell kommuniziert jeder Endpunkt direkt mit jedem anderen Endpunkt. Alle Teilnehmer in der Konferenz sind "`gleich"' - es gibt keinen Benutzer, der topologisch besonders ist oder über zusätzlichen Rechte oder Fähigkeiten verfügt. Jeder Teilnehmer kann jederzeit eine Konferenz betreten und verlassen. Das Audiosignal wird nur von den Endpunkten abgemischt.

Der Hauptvorteil ist, dass kein Endsystem mehr als einen Audiostrom encodieren muss. Jeder Benutzer dekodiert bis zu N-1 Audioströme einer N-Teilnehmer Konferenz, muss aber nur einen Audiostrom enkodieren. Für die meisten Sprach Codecs verursacht das Enkodieren mehr Last als das Dekodieren, was also zunächst nicht problematisch ist. 

In einer N-Teilnehmer Konferenz muss jedoch jeder Teilnehmer über genügend Bandbreite verfügen, um N-1 simultane Audioströme zu verschicken. Dadurch ist dieser Mechanismus für Systeme mit limitierten Bandbreiten wie analoge Modems oder asymmetrische DSL-Leitungen mit einem schwachen Upload nicht besonders gut anwendbar.

Das größte Problem bei diesem Ansatz stellt die fehlende strukturierte Signalisierung und Lokalisierung der Teilnehmer dar, da kein Knoten eine vollständige Information darüber besitzt, wer Teil einer Konferenz sein soll. Schulzrinne stellt in dem in Kapitel 5 vorgestellten Full-Mesh-Ansatz genau diese Problematik fest.

\subsection{Komplett zentralisierte Ansätze}
\label{zentralansatz}
Die in Kapitel 5 von Singh und Acharya vorgestellte Methode kann man als zentralisiertes SIP bezeichnen. Hier wird die Signalisierung und Lokation der Teilnehmer und das Abmischen der Audioströme zentral vorgenommen. Den komplett zentralisierten Ansatz verfolgen auch Safei und Boustead im vorgestellten MICE-System. Diese Architektur bietet zunächst eine sehr gute Ausgangsbasis für Sprachkommunikationslösungen mit einer begrenzten Anzahl an Teilnehmern, da es auch Knoten mit geringer Bandbreite eine Teilnahme ermöglicht. 

Die Grundlage für eine einfache Berechnung der verbrauchten Bandbreite versteht sich unter folgenden Voraussetzungen:

\begin{itemize}
	\item Jeder Spieler sendet einen Audiostrom zum Server.
	\item Jeder Spieler im gleichen Spiel möchte die gesprochenen Daten aller Spieler empfangen.
	\item Weil Spieleserver, Konferenzserver und Mixer zentralisiert sind, kann der Mixer die Audioströme zentral abmischen, da er auch die Positionen der Teilnehmer kennt. 
\end{itemize}

Befinden sich beispielsweise 16 Personen im Spiel, empfängt der Server Audio\-ströme von 16 Personen und sendet einen bereits abgemischten Audiostrom an jede der 16 Personen. 

Sendet jeder Spieler seinen Audiostrom mit einem Speex\footnote{Patentfreies Audio-Kompressions-Format (Xiph OSC) , Version 22.03.2008, http://speex.org} Audiocodec mit einer 16 Kbit/s Bitrate an den Server, der nach dem heutigem Standard mit einer 100MBit-Anbindung für den Upload und Download ausgestattet ist, würde sich folgende theoretische maximale Anzahl an gleichzeitigen Audioverbindungen ergeben:

\[
 \frac{100000 \frac{Kbit}{s}}{16 \frac{Kbit}{s}} = 6250 \, Spieler
\]

Der Client selbst muss also nur in der Lage sein, seinen eigenen Audiostrom zu senden und einen Audiostrom mit gleicher Bitrate zu empfangen. 

Zusätzlich zur Bandbreite wirkt auch die Rechenkapazität des Servers limitierend, da jedes der ankommenden Signale dekodiert, abgemischt und enkodiert werden muss. Eine Auswertung\footnote{Siehe Kapitel 10 evaluation.} der CPU Belastung des Mixers, die Anhand der Implementierung vorgenommen wurde, zeigt dass die Grenze von 6250 Spielern schon viel früher erreicht wird und so die theoretisch mögliche Anzahl an Spielern vor allem durch die hohe CPU-Belastung des Mixers begrenzt wird. 

Prinzipiell ist dieser Ansatz aber allen dezentralisierten Ansätzen überlegen, da die zentralisierte Komponente in der Regel über genügend Bandbreite verfügt, um viele Audioströme zu empfangen und zu versenden, während dies bei einfachen Clients oft zu Problemen führt. Zudem haben wir die Möglichkeit, die Lokation und Signalisierung der Teilnehmer zentral zu verwalten. Diese Architektur wird vor allem bei Telefonkonferenzen verwendet, bei denen die Endgeräte (VoIP Telefone) die über eine geringe Rechenleistung verfügen und auf das Abmischen des Audiosignals durch einen Konferenzserver angewiesen sind. 

Die Nachteile eines Mischservers liegen jedoch beim interaktiven Delay, der abhängig von der Position des Servers entsprechend schlecht ausfallen kann. Zudem ergeben sich Schwierigkeiten bei der Skalierbarkeit eines einzigen zentralen Audioservers, da dessen Bandbreite und Rechnerkapazität begrenzt sind. Dabei bietet es sich gerade im Spielebereich an, die hohe Rechenleistung von gut ausgestatteten Spielecomputern auszunutzen, um die zentrale Komponente zu entlasten. 

\subsection{Verteiltes dediziertes Audiomixing}

\subsubsection{Dedicated Node Mixing}
Die Konsequenz aus einer fehlenden Skalierbarkeit eines Audioservers führt zum logischen Entschluss diesen zu verteilen. Ein Ansatz verteilte Konferenzen zu betreiben, besteht darin, mehrere dedizierte SIP-Endpunkte zu ernennen, mit denen sich Teilnehmern  verbinden. Diese Mixer nehmen die Audioströme entgegen, mischen sie ab und leiten sie an die entsprechenden Spieler weiter. 

Dabei gibt es zwei mögliche Varianten dieses Modells: In einem End-System-Mixing übernimmt ein Teilnehmer die Verantwortung für das Mischen des Audiostroms und in einem Server-basierten Mixing übernehmen unabhängige dedizierte Knoten diese Verantwortung, ohne aktiv am Gespräch teilzunehmen. 

Die Vorteile liegen vor allem in der Verteilung der Bandbreiten- und Kapazitätsbelastung auf mehrere Maschinen. 

Dieses Modell hat jedoch einige Nachteile: Die Existenz einer Konferenz ist ab\-hän\-gig von dem Vorhandensein eines Mix-Servers.Was die maximale Anzahl an Spielern angeht, ergeben sich hier prinzipiell für jeden Mischknoten die gleichen Berechnungen wie bei einem einzigen Server System (siehe Abschnitt \ref{zentralansatz}). Deshalb muss von Knoten ausgegangen werden, die über genügend Bandbreite und Rechenkapazität verfügen, um für andere Spieler das Mischen vorzunehmen. 

Ebenfalls problematisch gestaltet sich der Übergang von einem einfachen Telefongespräch zwischen zwei Teilnehmern zu einer Konferenz, da zuerst alle Teilnehmer den gleichen Server aufsuchen müssen, um diesem dann die Kontrolle über die Konferenz zu übergeben. Dies ist keine einfache Aufgabe und erfordert ein ausgeklügeltes Vorgehen. Der im Kapitel 5 vorgestellte Ansatz von Gu beschäftigt sich mit der Kontrolle von dedizierten \textit{Superpeers}, die das Mischen vornehmen, geht jedoch nicht auf das Problem ein, wie Teilnehmer lokalisiert werden sollen und wie die Übergänge zwischen Konferenzen stattfinden sollen.

Erschwerend hinzu kommt das Problem der Korrelation zwischen den Lokationen der Spieler und der Lokation solcher Mischserver, das in Abschnitt \ref{Audio-Proxy} behandelt wurde. 

Grundsätztlich jedoch funktioniert das dedizierte Mischen besser als das End-System-basierte, da die Systeme meist zuverlässiger sind und über eine bessere Anbindung verfügen. Für größere Konferenzen bietet sich diese Art des Mischens an, für kleinere jedoch bedeutet sie einen erheblichen Aufwand.
% Grafik End-System-Mixing
% Grafik Server-Based-Mixing

\subsection{Dezentrales Audiomixing}
\subsubsection{SIP-Hybrid-Modell}
\label{siphybrid}

Das SIP-Hybrid-Modell nutzt die zentrale Komponente des Registrars, bei dem sich jeder Teilnehmer des Spiels zuerst anmeldet. Der Registrar verfügt so über eine komplette Liste aller Teilnehmer. Der Datenaustausch findet über den Proxy statt, der bei jeder Nachricht die Adresse des Empfängers bestimmt. Die Sprach\-kommunikation jedoch findet nicht über die zentrale Komponente statt, sondern direkt zwischen den einzelnen Spielern. Im einfachsten Fall wird der eigene Audiostrom an alle Teilnehmer des Spieles gesendet, und man selbst empfängt auch den Audiostrom aller Teilnehmer. In einer peer-to-peer Telekonferenz nutzt jeder Teilnehmer unicast, um seine Stimme an alle anderen Teilnehmer der Konferenz zu übertragen und um Stimmen aller Konferenzeilnehmer zu empfangen. In einer Konferenz mit $n$ Teilnehmern müssen so $n^2-n$ Audioströme ausgetauscht werden. 

Dies entspricht dem Full-Mesh-Anatz von Schulzrinne \cite{schulzrinne03}, der jedoch in einem völlig dezentralisierten Ansatz damit zu kämpfen hatte, die Teilnehmer einer Konferenz zu bestimmen. Hier kann die Bestimmung der Teilnehmer einer Konferenz mit Hilfe des Registrars zentral geschehen und vereinfacht das Problem. 

Indem nun die einzelnen Knoten für das Abmischen verantwortlich sind, kann die Kapazitätsbelastung eines Mischservers auf die Clientmaschinen verlagert werden, die gerade im Spielebereich sehr gut ausgesattet sind. Da allerdings der Bandbreitenverbrauch bei einem dezentralen Austausch von Audioströmen quadratisch von der Anzahl der Teilnehmer abhängt, soll eine Plausibilitätsrechnung prüfen, welche Mindestvoraussetzungen die Teilnehmer eines solchen Systems erfüllen müssen.

Es wird gefordert, dass mindestens 16 Spieler in der Lage sein sollen, miteinander zu kommunizieren. Sendet jeder Spieler seinen Audiostrom mit 16 Kbit/s an die anderen Spieler, kann leicht errechnet werden, über welche Anbindung die Spieler mindestens verfügen müssen, um diese Anforderung zu erfüllen. 

Die Grundlage für eine einfache Berechnung bieten die folgenden Voraussetzungen:

\begin{itemize}
	\item Jeder Spieler sendet einen Audiostrom an alle Clients.
	\item Jeder Spieler im gleichen Spiel möchte die Audioströme aller Personen empfangen.
	\item Jeder Spieler mischt die Audioströme lokal ab, da er auch die Positionen der Teilnehmer kennt. 
\end{itemize}

Befinden sich beispielsweise 16 Personen im Spiel, empfängt jede dieser 16 Personen 16 Audioströme und sendet auch seinen eigenen Audiostrom an jede der 16 Personen. 

Upstream/Downstream:

\[	
	\mbox{16 Spieler} \cdot 16 \frac{Kbit}{s} = 256 \frac{Kbit}{s}
\]

Das würde für dieses Szenario bedeuten, dass theoretisch bei 16 gleichzeitigen Spielern jeder Spieler mindestens über einen Upload/Download von $256 Kbit/s$ verfügen muss, um in einem Full-Mesh miteinander kommunizieren zu können. Der Full-Mesh Ansatz hat das Problem, dass sich die Kapazität der Bandbreite relativ schnell erschöpft, da jeder Spieler seinen Audiostrom an alle anderen Spieler senden muss. Geht man davon aus, dass jeder Client heutzutage mit einem Upload von 128 Kbit/s ausgestattet ist, zeigen sich bereits bei 16 Spielern, die Grenzen dieses Systems. Mit entsprechenden Audiocodecs ist vielleicht eine Verdopplung der Teilnehmer möglich, sie ändern aber nichts an den architekturbedingten Grenzen dieses Ansatzes.

Die Gründe dafür liegen unter anderem in einer uneffizienten Verbreitung des Audiostroms. Es ist vorstellbar, dass nicht nicht jeder Spieler des Spiels am Audiostrom aller Mitspieler interessiert ist. Trotzdem werden mit allen Teilnehmern Verbindungen aufgebaut.

\subsection{Hörnähe vs. Area of Interest}
Da bereits in Kapitel 2 festgestellt wurde, dass Spieler nur an manchen  Audioströmen von Spielern interessiert sind, wird versucht diese Beobachtung in die Modellierung einfließen zu lassen. Muss jeder Teilnehmer seinen Audiostrom nicht an alle anderen Teilnehmer verschicken, sondern nur an Teilnehmer seiner unmittelbaren Umgebung, so kann Bandbreite eingespart werden. Außerdem kann in Abhängigkeit der Entfernung der Spieler zueinander, unterschieden werden welcher Audiocodec eingesetzt wird. 

Dieser Ansatz entspricht dem Proximitätsprinzip, oder auch der \textit{Area of Interest}, bei der nur Teilnehmer an einer Audioverbindung interessiert sind, die sich auch tatsächlich in der Nähe des Spielers befinden.

Die Grundlage für eine einfache Berechnung versteht sich unter folgenden Voraussetzungen:

\begin{itemize}
	\item Jeder Spieler sendet einen Audiostrom an Teilnehmer in seiner Hörnähe. 
	\item Jeder Spieler befindet sich mit einer Wahrscheinlichkeit $P_{Hoernaehe}$ in der Hörnahe des Teilnehmers. 
	\item Jeder Spieler mischt die Audioströme lokal ab, da er auch die Positionen der Teilnehmer kennt. 
\end{itemize}

Befinden sich beispielsweise 16 Personen im Spiel und nimmt man an, dass sich im Schnitt nur $30\%$ aller Teilnehmer in Hörnähe aufhalten, so muss der Sender nur noch an 5 Personen seinen Audiostrom senden und auch nur von 5 Personen den Audiostrom empfangen. 

Dabei gibt $P_{Hoernaehe}$ an, wie viele Personen, sich im Schnitt in der Hörnähe des Teilnehmers befinden. Dieser Wert kann verändert werden, in dem die \textit{Hörer\-reichweite} des Spielers vergrößert oder verkleinert wird. 

Generell gilt je größer die Hörerreichweite, desto mehr Personen können sich in der Hörnähe des Teilnehmers befinden. In diesem Fall wird bei einer Hörerreichweite von 10 m, eine theoretische Wahrscheinlichkeit, dass eine Person sich in diesem Hörradius befindet von 30\% angenommen. 

Nun wird die Gleichung um diese Wahrscheinlichkeit ergänzt und immer noch von 16 Spielern im Spiel ausgegangen. 

Upstream/Downstream:

\[
	\mbox{16 Spieler} \cdot 16 \frac{Kbit}{s} \cdot 30\% = 76,8\frac{Kbit}{s}
\]

In Abhängigkeit der Wahrscheinlichkeit ist eine Reduzierung der Bandbreite möglich. Natürlich kann im schlechtesten Fall, bei einer hohen Avatardichte, der Fall eintreten, dass wieder alle 16 Teilnehmer sich in der Hörnähe des Spielers befinden. Dann ist diese Lösung genauso effizient wie die Full-Mesh-Topologie, da der Spieler mit allen Teilnehmern Verbindungen aufbauen muss. Im Schnitt kann jedoch ein großer Prozentsatz der Bandbreite eingespart werden, wenn man davon ausgeht, dass Spieler nur an Audioverbindungen mit Spielern interessiert sind, die sich in ihrer Nähe befinden.

Es lässt sich sogar noch mehr Bandbreite einsparen, wenn man die Hörreichweite in zwei Zonen (entsprechend Abschnitt \ref{proxemikalssteuerungvonkonferenzen}) mit verschiedenen Audiocodecs unterteilt. In einer private Zone wird ein hochwertiger Audiocodec mit einer größeren Bandbreite benutzt und in einer sozialen Zone ein wird ein Codec mit einer niedrigeren Bandbreite benutzt. 

In einem einfachen Szenario, kann man annehmen, dass die 30\% aller Benutzer in Hörreichweite, sich zu 10\% in der privaten Zone und zu 20\% in der sozialen Zone aufhalten. Spieler in der privaten Zone nutzen einen Audiocodec mit einer Bitrate von $16Kbit/s$ und Spieler in der sozialen Zone einen Audiocodec mit $8Kbit/s$. Ergänzt man die Gleichung entsprechend um das Zonenkonzept, und nimmt immer noch an, dass sich 16 Spieler im Spiel befinden kommt man zu folgender Berechnung:

\[
	\mbox{16 Spieler} \cdot 16 \frac{Kbit}{s} \cdot 10\% + \mbox{16 Spieler} \cdot 16 \frac{Kbit}{s} \cdot 20\% = 51,2\frac{Kbit}{s}
\]

Hier wird deutlich, dass noch einmal Bandbreite eingespart werden kann, und trotzdem die gleiche Konnektivität gewährleistet wird. Die Einsparung resultiert vor allem aus der Reduziertung der Audioqualität der sozialen Zone. Trotzdem kann bei Bedarf noch eine höherwertige Konversation eingeleitet werden, indem sich Spieler in die private Zone begeben. Im Kapitel 7 und 9 wird die Umsetzung dieses Ansatzes genauer diskutiert und evaluiert.

\subsection{Einsatz mehrerer Server}
\label{mehrereregistrare}
Die vorgestellten Alternativen $A_{5}$ und $A_{6}$, gehen davon die zentrale Komponente des Registrars verteilbar ist. Von einer Verteilung des Registrars und Proxy können auch die vorgestellten Alternativen $A_{1}$, $A_{2}$, $A_{3}$ profitieren, da sich damit die \textit{Fault Tolerance} des Systems erhöht. Falls mehrere Registrare eingesetzt werden, bestehen folgende Alternativen:

\begin{itemize}
	\item Die Registrierung des Benutzers findet auf einem Registrar statt und wird dann auf mehrere Registrare repliziert. Die Suche findet bei einem beliebigen Registrar statt.
	\item Die Registrierung geschieht nur auf einem Registrar, während die Suche nach dem Registrar, der die Benutzerinformation enthält vom Client auf allen Registraren stattfindet.
\end{itemize}

% BILD see \cite{schulzrinne05}

Im ersten Fall könnten durch Datenbank-Replikationen sichergestellt werden, dass die Benutzereinträge zwischen verschiedenen Registraren konsistent gehalten werden. 

Im zweiten Fall kann entweder der Benutzer alle Registrare kontaktieren oder der erste kontaktierte Server die Anfrage weiterleiten. 

Der Nachteil des ersten Ansatzes ist eine erforderliche Synchronisation für jede Registrierung. Es besteht die Möglichkeit, dass Einträge veraltet sind, bevor eine Synchronisation zwischen den Servern ausgeführt wird. Mit einer wachsenden Anzahl an Benutzern könnte der zusätzliche Netzwerkverkehr zwischen den Servern zu einem Flaschenhals werden. 

Im anderen Fall ist die Verbindungslatenz höher, da erst eine Reihe von Schritten durchlaufen werden muss. Eine parallele Suche erhöht zudem die benötigte Bandbreite. 

Beide Ansätze können jedoch fehlschlagen, wenn die Anzahl an Benutzern sehr groß wird.

\section{Implementierung einer hybriden Architektur}
Im darauf folgendem Kapitel wird die Implementierung der Alternative $A_{3}$ besprochen, da diese Kombination es erlaubt die in Kapitel 3 gestellten Ziele zu realisieren und gleichzeitig Möglichkeiten bietet Bandbreite einzusparen, die bei Peer-to-Peer sehr kostbar ist. Deswegen wird auch der in Abschnitt \ref{proxemikalssteuerungvonkonferenzen} gewählte Proxemikansatz gewählt, um die Anzahl an Verbindungen zwischen den einzelnen Clients zu reduzieren. Außerdem sprechen noch viele weitere Vorteile für die Präferenz dieser Alternative:

\begin{itemize}
	\item Eine einfache Lokation und Signalisierung der Teilnehmer
	\item Die Bandbreite auf den Registraren und Proxys ist minimal, während der Audiostrom zwischen den Clients stattfinden kann.
	\item Sie bietet eine gute Basis um später die zentrale Komponente des Registrars auch verteilt zu implementieren. Somit ist eine zukünftige komplett dezentralisierte Umsetzung der Alternative $A_{9}$ mit P2PSIP möglich.
	\item Sie bietet eine gute Ausgangsgrundlage, um die alternative $A_{6}$ umzusetzen, wenn mehrere Registrare und Proxys eingesetzt werden.
	\item Man umgeht das komplizierte Problem einer dezentralen Signalisierung des Full-Mesh-Ansatzes.
	\item Es können mehrere Unterschiedliche Kanäle gleichzeitig betrieben werden.
	\item Der Spieler ist in der Lage zu unterscheiden, welche Audioströme er abmischen will und welche er verwerfen will.
\end{itemize}