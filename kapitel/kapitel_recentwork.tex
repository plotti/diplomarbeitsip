\chapter{Verwandte Arbeiten}


\section{Historische Ansätze}
Erste Arbeiten die sich mit Audio in Computerspielen auseinander setzen haben ihren Ursprung in den SPLINE \cite{carlsson93} und DIVER \cite{anderson95} Systemen. Diese sehen vor, dass sich Clients sich mit einem zentralen Server verbinden um Spielerpositionen auszutauschen. Spieler erhielten zwar eine lokalisierte Audioszene entsprechend ihrer Position, konnten jedoch keine Sprachkommunikation untereinander aufbauen. 

Erste Ansätze für eine Sprachkommunikation in Computerspielen finden sich im MiMaze Spiel \cite{diot99}. Mimaze war entwickelt worden um Übertragungs und Kontrollmechanismen in Internet Spielen zu erforschen. Der Anatz sah vor, dass der Datenaustausch zwischen Spielern und Server Mittels TCP stattfand und zwischen den Spielern untereinander mittels UDP und Multicast Gruppen etabliert wurde. Dabei wurde die Spielewelt auf dem Server verwaltet und jegliche Aktionen im Spiel mit UDP Multicast Gruppen zwischen den Spielern ausgetauscht. Bolot und Fosse-Parisis versuchten in \cite{bolot98} in die bestehende Architektur des MiMaze Spiels um die Sprachkommunikation zu erweitern. Dazu schlugen sie vor das RTP und RTCP Protokoll einzusetzen und die empfangenen Audioströme auf den Clients zu lokalisieren. Aufgrund der schwierigen Koordination der Audioströme und deren Synchronisation mit der Spielewelt blieb der Einsatz von Sprachkommunikation in Computerspielen zunächst ein Entwurf. 

\section{Serverbasierte Ansätze}

\subsection{DICE: Internet Delivery of Immersive Voice Communication for Crowded Virtual Spaces}

Im DICE System \cite{safei05} schlagen Safei und Boustead einen Entwurf einer serverbasierten Architektur für die Sprachkommunikation für Mehrspieler Spiele im Internet vor. Dieses System beruht auf dem Prinzip dass eine zentrale Komponente für die Verteilung von Audioströmen verantwortlich ist, deren Abmischen jedoch lokal auf den Clients geschieht. Dabei soll jeder Spieler eine Mischung aus Stimmen und Geräuschen hören, die speziell auf seine Position im Spiel angepasst ist. Es soll nicht nur die Lautstärke als auch die Position der Geräusche in der Audioszene gerendert werden. Die Architektur baut auf einem verteiltem Server System auf, da vorhergehenden Studien \cite{safei04} von Safei gezeigt haben, dass eine einzige Serverkomponente die Delay Anfoderungen nicht erfüllen kann. 

Die Elemente des Systems bestehen aus einem Audio Client, der seinen mono Audiostream an den Scene Creation Server schickt, und alle bestehenden Audioströme von ihm empfängt. Der Audio Client ist anhand der Postionen der Avatare im Spiel in der Lage die empfangenen Audioströme räumlich zu positionieren. 

Auf dem Scene Creation Server wird das räumliche Umfeld jedes Spielers in Cluster eingeteilt, die nur Spieler beinhalten deren Entfernung und Winkel zum Spieler ähnlich sind. Spieler die sich im gleichen Cluster befinden werden von diesem in einen Audiostrom zusammengemischt und an an den ensprechenden Audioclient inklusive der Positionsinformationen dieses Clusters weitergeleitet. Diese Methode soll dafür sorgen, dass nicht alle Audioströme separat an den Audioclient gesendet werden müssen und eventuell gebündelt werden können und so Bandbreite eingespart werden kann. Dabei wird ein maximaler Distanz und Winkelfehler zugelassen, der zwar die Qualität der exakten Positionierung vermindert, aber es erlaubt mehrere Spieler in das gleiche Cluster zu mischen und so Bandbreite zu sparen. 

Der Scene Creation Server wird dabei vom drunterliegenden Control Server verwaltet, der darüber entscheidet welche Audioströme an den Audio Client geschickt werden sollen, damit dieser in der Lage ist die Audioszene zu erzeugen. 

\subsection{MICE: Mobile Immersice Communication Environment}

Das MICE System \cite{safei06b} von Safei und Boustead zielt auf den Entwurf einer serverbasierten Sprachkommunikation für Mehrspieler Spiele die auf mobilen Endgeräten zum Einsatz kommen. Die spezielle Herausforderung besteht daraus, dass solche Geräte über eine geringe Bandbreite und Rechenleistung verfügen. Dabei ist der Ansatz ähnlich dem DICE System, da auch jeder Spieler seine Monoquelle an den Server sendet. Der Unterschied zum DICE System besteht darin, dass die Erzeugung der Audioszene komplett auf dem Server geschieht und nur das fertige Resultat als stereo Aduiostrom an den Client übertragen wird. 
Dazu wird Mittels HRTF (Head Related Transfer Function) \cite{bergault94}, einer Technik die es erlaubt Klänge im dreidimensionalen Raum zu positionieren eine Audioszene erzeugt. Für das rechte und linke Ohr werden jeweils zwei verschiedene Signale erzeugt, aus deren Unterschied das menschliche Ohr die Quelle im Raum positionieren kann. Für die Berechnung der HRTF Funktion benötigt man die Richtungsvektoren aller Quellen. Ähnlich wie im DICE Ansatz schlagen Safei und Boustead vor ein Clustering vorzunehmen und für Spieler mit ähnlicher Position und Richtungsvektor einen Gesammtrichtungsvektor zu benutzen. Dadurch entsteht auch wie beim DICE System ein Distanz- und Winkelfehler den sie jedoch mit Hilfe eines Linearen Optimierungsproblems unter einen expermimentell festgelegten Schwellwert minimieren. Dieser Schwellwert wird für Audioquellen niedriger gesetzt als für Quellen die weit entfernt sind da Untersuchungen gezeigt haben dass in Abhäniggkeit von der Enfernung ein verschieden großer Fehler von Probanten akzeptiert wird \cite{safei06} \cite{safei07}. 

Dazu wurden die Erfahrungen von 27 Probanten Anhand des Standardisierten Mean Opition Score \cite{mtu96} analysiert und es wurde festgestellt, dass Unterschiede bis zu 35 $\circ$ Grad akzeptiert werden. In einer weiteren Studie schlagen Safaei und Downlatshahi vor die zentralisierte Server Architektur durch eine Anzahl an lokalen Proxies zu ersetzen, die selbst in einem Multicast Overlay verbunden sind \cite{safaei06}. 

\subsection{Session Initiation Protocol for Multiplayer Networked Games}

Singh und Acharya schlagen ein auf dem Session Initiation Protocoll  basiertes System vor um VoiP in Mehrspieler Spielen zu realisieren \cite{singh04}. Dazu führen sie einen Konferenz Server ein, der eng mit dem Spieleserver zusammenarbeitet. Der Konferenzserver kontrolliert und initiert die Sitzungen für alle Spielteilnehmer und verwaltet ebenfalls die Mixerkomponente des Systems. Diese ist zuständig ist für das dedizierte mischen der Verschiedenen Audioströme. Dabei wird die Konferenz zwischen den Clients und dem Konferenzserver initiert, der Datenstrom selbst jedoch fließt zwischen dem Mixer und den Clients. 

In einem zentralisierten Ansatz läuft die Spielelogik auf dem Spieleserver und sorgt dafür, dass Spieler Konferenzen in Abhängigkeit ihrer Position auf dem Spielfeld betreten. Das Spielfeld wird in mehrere Zonen aufgeteilt für die im Konferenzserver Konferenzen reserviert werden.
 
In einem Dezentralisierten Ansatz enthalten die Clients die Spielelogik, die sie veranlasst entsprechend mit dem Konferenzserver Konferenzen zu initiieren. 

In beiden Fällen wird zwischen einem statischen und dynamischen Ansatz unterschieden. Im statischen Ansatz existiert eine Konferenz für jedes Team, die vom ersten Teilnehmer der Konferenz initiiert wird und während der gesamten Spielzeit aufrechterhalten wird. 

Im dynamischen Ansatz wird in Abhängigkeit der Position des Spielers vom Gameserver der Konferenzserver veranlasst den Spieler in eine entsprechende Konferenz zu verbinden. So können für verschiedene Räume oder Orte verschiedene Konferenzen existieren. Dabei findet der Übergang von einer Konferenz zur anderen für den Spieler selbst nahtlos statt, da die Signalisierung nur zwischen Gameserver und Konferenzserver bzw. Mixer stattfindet. 

In fortführenden Studien \cite{singh05} \cite{singh06} diskutieren Singh und Archaya eine Erweiterungen des SIP Ansatzes für interpersonelle Konferenzen. Sie schlagen vor ihr bestehendes System so zu erweitern, dass jeder Spieler seine eigene Konferenz auf dem Server besitzt die speziell nur für Ihn alle Stimmen in seiner Hörnähe enthält und eine weitere Konferenz die seine Stimme für andere Spieler enthält.

Wichtig hierbei ist dass der Spieler zwar sein Audiosignal an die zweite Konferenz sendet, diese aber nicht hören will da sie für die Mitspieler bestimmt ist. Das gewünschte Verhalten für die zweite Konferenz ähnelt somit einer Ein-Weg-Konferenz.
Da SDP jedoch keine Ein-Weg-Konferenzen erlaubt, wäre erst in einem erweiterten SIP Standard dieses Szenario vorstellbar. 

Eine weitere theoretische Erweiterung sieht vor, dass die Lautstärke des Audiostreams von Spielern in der Hörnähe in Abhängigkeit von ihrer Distanz variert werden soll, wobei  ein ungelöstes Probleme bei diesem Ansatz die Komponente des Mixers bleibt. Dieser müsste um die Möglichkeit erweitert werden Distanzvektoren in den Mischvorgang einzubeziehen. 

%\subsection{SIP und SOAP basiertes Konferenzframework}
%In einem anderen zentralisierten Ansatz \cite{schulzrinne02} schlagen Schukzrinne und Koskelainen ein Framework zur Kontrolle von Konferenzen vor das auf den SIP und SOAP( Simple Object Access Protocol) Standards basiert. Während SOAP für die Kontrolle der Konferenzen verwendet wird findet der Aufbau der einzelnen Sitzungen im SIP Protokoll statt. 

\section{Dezentralisierte Ansätze}

\subsection{Full-Mesh}

In \cite{schulzrinne03} \cite{schulzrinne99} schlagen Schulzrinne et. Al ein verteiltes dezentralisiertes Protokoll vor, in dem alle Teilnehmer ein komplett verbundenes Netz (engl. full-mesh )bilden. Hier ist jeder Teilnehmer mit jedem anderen Teilnehmer verbunden. Dazu überträgt jeder Teilnehmer seinen Adudiosstrom an alle anderen Teilnehmer, die dann lokal das Abmischen vornehmen. Um den Ansatz zu testen, simulieren sie ein solches Netz in verschiedenen Szenarien in denen Teilnehmer  Konferenzen betreten, verlassen oder andere Teilnehmer zu Konferenzen einladen. Die Teilnehmer selbst haben keinerlei Information über die Topologie des Netzes und  können so nur durch das rekursive Einladen von Teilnehmern ein komplettes Netz bilden. Das Hauptproblem dabei ist, dass dadurch eine Vielzahl an Ereignismöglichkeiten existiert die eintreten können. Schulzrinne et Al. zeigen, dass schon bei vier Teilnehmern, die Einladen, das Spiel verlassen oder Betreten bereits über 50 Möglichkeiten aus den genannten Permutationen möglich sind. 


\subsection{Distributed Partial Mixing}

Radenkovic, Grennhalgh und Benford diskutieren  in \cite{radenkovic02} den Einsatz 
eines DPM (Distributed Partial Mixing), der auf Basis des RTP und RTCP Protokolls und Multicast Gruppen funktioniert. Hier werden mehrere dedizierte Mixer eingesetzt, die nur solche Audiostreams abmischen, die tatsächlich auch vom Teilnehmer benutzt werden. Dies soll mit einerseits ermöglichen eine Vielzahl an Audioströmen zu verwalten und andererseits die Überlastung Netzwerks verhindern. 

Der Ansatz sieht vor, dass die dedizierten Mixer zunächst die Audioströme der Clients entgegennehmen. Die Mixer selbst sind alle miteinander in einer Baumstruktur verbunden und in der Lage Audioströme untereinander weiterzuleiten. Je nach Konnektivität und Bandbreite der Mixer untereinander entscheiden diese, ob ein Zusammenmischen der Audioströme notwendig ist, oder alle Audioströme ungemischt weitergeleitet werden können. Da der Ansatz auf Multicast Gruppen basiert ist er zwar in LANs umsetzbar im Internet jedoch aufgrund der fehlenden Multicast Unterstützung nicht realisierbar. 

\subsection{Verteiltes Mischen}

Gu, Yu und Shae schlagen ein dezentrales System vor \cite{gu05} in dem sie die Verteilung des Audiostroms in zwei Phasen der Aggregation und Distribution aufteilen. Dabei verstehen sie unter Aggregation das Zusammenmischen der Audioströme und unter Distribution die Verteilung der gemischten Audioströme auf die einzelnen Clients. 
Dazu nimmt ein initialer Mischknoten, der eine gute Anbindung besitzt und möglichst optimale Wege zu allen Teilnehmer hat zunächst das Abmischen vor. Falls er jedoch überlastet ist, kann er zusätzliche Mischknoten ernennen, die seine Arbeit übernehmen. Dabei können Mischknoten falls sie unterlastet sind ihre Aufgabe an den Vaterknoten wieder abgeben. Der Vorteil der Methode ist, dass kein zentraler Mischserver benutzt werden muss, sondern theoretisch jeder Knoten diese Aufgabe übernehmen kann. 

Der Hauptnachteil dieser Methode ist, dass jederzeit alle Knoten über die Topologie des Netzes informiert sein müssen und jederzeit den den optimalen Mixknoten der Multicast Gruppe kennen müssen. Die Distribution des Audiostreams und die Kontrolle der Clients darüber welche Audioströme gemischt werden sollen wird nicht gelöst. 
%TODO

\subsection{SIP Konferenz Extension}

In \cite{miladinovic-multiparty} diskutieren Stadler and Miladinovic sowohl den serverbasierten als auch eine dezentralen Einsatz von SIP für Konferenzen vor. Dazu führen sie einen SIP Nachrichtentyp CONF ein der vom Initiator der Konferenz an alle Teilnehmer der Konferenz verschickt wird und alle Namen und den Status aller Konferenzteilnehmer enthält. 

Im serverbasierten Ansatz werden die Audioströme auf einem Konferenzserver gemischt und an die Teilnehmer versendet, im dezentralen Ansatz wird zwischen den Teilnehmern eine full-mesh Topologie aufgebaut. Problematisch bei diesem Ansatz ist jedoch dass Clients nur Teilnehmer einer einzigen Konferenz sein können und ein nahtloser Wechsel zwischen Konferenzen nicht möglich ist. Zudem ist die Einführung eines neuen SIP Nachrichtentyps erforderlich.